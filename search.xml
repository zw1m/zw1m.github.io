<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[内存性能测试及分析]]></title>
    <url>%2F2019%2F05%2F%E5%86%85%E5%AD%98%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%8F%8A%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[基础知识CPU体系构成Node -&gt; Socket -&gt; Core -&gt; Logical Processor/Thread 一个NUMA Node可以有一个或者多个Socket（也称为多路CPU），一个多核Socket显然包含多个Core，一个Core如果打开HT则变成两个Logical Processor（也称为Thread）。两个Logical Processor只是OS内部看到的，还是属于同一个Core。 HT是使用的流水线技术，但是两个Logical Processor仍然共享Core的执行单元，所以计算密集型应用从HT技术上没有收益。 MEM体系构成channel -&gt; DIMM -&gt; rank -&gt; chip -&gt; bank -&gt; row/column 举例：一个i7 CPU支持两个Channel（双通道），每个Channel上可以插俩个DIMM，而每个DIMM由两个rank构成，8个chip组成一个rank。由于现在多数内存颗粒的位宽是8bit，而CPU带宽是64bit，所以经常是8个颗粒可以组成一个rank。内存条2R X 8的意思是由2个rank组成，每个rank有8个内存颗粒。 Chip拆开来看，它是由8个Bank组成，每个Bank核心是个一个存储矩阵，就像一个大方格子阵。这个格子阵有很多列（Column）和很多行（Row），这样我们想存取某个格子，只需要告知是哪一行哪一列就行了。 延迟及cycles 各种寄存器，用来存储本地变量和函数参数，访问一次需要1 cycle，耗时小于1ns； L1 Cache，一级缓存，本地 core 的缓存，分成 32K 的数据缓存 L1d 和 32k 指令缓存 L1i，访问 L1 需要3 cycles，耗时大约 1ns； L2 Cache，二级缓存，本地 core 的缓存，被设计为 L1 缓存与共享的 L3 缓存之间的缓冲，大小为 256K，访问 L2 需要 12 cycles，耗时大约 3ns； L3 Cache，三级缓存，在同插槽的所有 core 共享 L3 缓存，分为多个 2M 的段，访问 L3 需要 38 cycles，耗时大约 12ns； Memory，访问需要 120-240 cycles，耗时大约 60-120ns； 测试工具streamStream是内存带宽及延迟性能的测试工具。官网如下： http://www.cs.virginia.edu/stream/ 源码地址，最新的版本是v5.10，2013-01-17。 http://www.cs.virginia.edu/stream/FTP/Code/ 基于stream的自动化测试工具，免配置 https://github.com/gregs1104/stream-scaling 参考资料：HPC高性能计算项目Stream内存带宽测试报告.docx https://max.book118.com/html/2018/1103/8143026101001131.shtm 环境还是我的这台台式机。2条DDR4内存，每条8GB，运行在3000MT/s，双通道。理论最大带宽：3000MT/s 64bit / 8bit / 1024 2 = 46.875GB/s123456789101112131415[root@MiWiFi-R4A-srv ~]# perl hwconfig hwconfig: warning: cpu0/cpufreq/scaling_governor should be &apos;ondemand&apos;, not &apos;powersave&apos;; see http://tiny.corp.hwconfig.com/xNR1csSummary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.3GB / 16GB 3000MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.3GB / 16GB 3000MT/s DDR4 == 2 x 8GBDisk: sda (scsi1): 100GB (15%) JBOD == 1 x 100GB SATA 300MB/s INTEL-SSDSA2BZ100G3Disk: sdb: 100GB JBOD == 1 x 100GB SATA 300MB/s INTEL-SSDSA2BZ100G3Disk-Control: ahci0: Intel 200 Series PCH SATA controller [AHCI mode]Network: 00:1f.6 (e1000e0): Intel Ethernet Connection (2) I219-VNetwork: 02:00.0 (igb0): Intel I211 GigabitNetwork: 03:00.0 (iwlwifi0): Intel Dual Band Wireless-AC 3168NGW [Stone Peak]OS: Fedora 30 (Thirty), Linux 5.0.7-300.fc30.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R4A-srv 原理 stream申请了 a[], b[], c[] 三个巨大的数组进行四种数学运算。四种数学运算如下： Copy: c = a; Scale: b = 3 * c; Add: c = a + b; Triad: a = b + c * 3; 每个数组元素默认是double型，占用8个字节。 stream具有空间局部性，对TLB、Cache友好。为了避免干扰，数组的大小要超过CPU三级缓存的大小。官方推荐是4倍。我的机器三级缓存是9216KB。 1234cat /sys/devices/system/cpu/cpu5/cache/index3/level 3cat /sys/devices/system/cpu/cpu5/cache/index3/size 9216K 修改STREAM_ARRAY_SIZE这个变量可以改变数组大小，我这里算法如下：三级缓存9216KB乘以1024换算成字节，再除以每个数组元素8字节，再乘以官方推荐的4倍。12&gt;&gt;&gt; 9216 * 1024 / 8 * 44718592 STREAM_ARRAY_SIZE=4718592 就是适合我这台机器的配置。4718592乘以每个数组元素8字节，就是下文每个数组的36MB，由于有abc三个数组，所以需要108MB的内存空间。1234Array size = 4718592 (elements), Offset = 0 (elements)Memory per array = 36.0 MiB (= 0.0 GiB).Total memory required = 108.0 MiB (= 0.1 GiB).Each kernel will be executed 10 times. 在5.10版本的stream里，STREAM_ARRAY_SIZE默认是10000000，作者说在20MB的三级缓存以内，都是适用的。 另外，STREAM_ARRAY_SIZE要足够大，超过20个clock-ticks，也就是CPU cycles。在测试的时候会提示，在Linux下一般都没有问题。 12345Your clock granularity/precision appears to be 1 microseconds.Each test below will take on the order of 5926 microseconds. (= 5926 clock ticks)Increase the size of the arrays if this shows thatyou are not getting at least 20 clock ticks per test. 对于多核系统，加上 -fopenmp 这个编译参数。 1gcc -O -fopenmp stream.c -o stream_omp #pragma命令是向编译器提供额外信息的标准方法，#pragma omp parallel for告诉编译器使用OpenMP自动以多线程的方式运行for循环中的内容，需要注意数据不存在依赖。 123#pragma omp parallel for for (j=0; j&lt;STREAM_ARRAY_SIZE; j++) c[j] = a[j]; 可以看到-O3优化级别，在Copy这项测试上性能有较大的提升。 1234[root@MiWiFi-R4A-srv stream-scaling]# gcc -O2 stream.c ;./a.out | grep CopyCopy: 22346.5 0.007202 0.007160 0.007232[root@MiWiFi-R4A-srv stream-scaling]# gcc -O3 stream.c ;./a.out | grep CopyCopy: 32212.8 0.004978 0.004967 0.004990 性能测试直接进行测试，多线程场景下，Copy性能反而下降： 这个问题先放在这里。多线程情况下，存在更多其它开销，影响了性能，待求证具体开销在哪里，可能是context-switches。12345678910111213[root@MiWiFi-R4A-srv stream-scaling]# gcc -O3 stream.c;./a.out | grep -E &apos;(Function|Copy:|Scale:|Add:|Triad:)&apos;Function Best Rate MB/s Avg time Min time Max timeCopy: 32532.9 0.004924 0.004918 0.004932Scale: 21560.4 0.007441 0.007421 0.007469Add: 24615.1 0.009767 0.009750 0.009789Triad: 24394.9 0.009858 0.009838 0.009890[root@MiWiFi-R4A-srv stream-scaling]# gcc -O3 -fopenmp stream.c;./a.out | grep -E &apos;(Function|Copy:|Scale:|Add:|Triad:)&apos;Function Best Rate MB/s Avg time Min time Max timeCopy: 30512.4 0.005257 0.005244 0.005268Scale: 22475.3 0.007143 0.007119 0.007170Add: 24577.2 0.009786 0.009765 0.009806Triad: 24460.1 0.009828 0.009812 0.009842 也可以使用stream-scaling测试性能即可。这个脚本识别CPU核心数，通过测试不同核心数下的性能。通过读取CPU的cache大小，计算出合适的STREAM_ARRAY_SIZE。 但是在我这台机器上，没有考虑三级缓存是同一个Socket的6个core共享这个情况，重复计算了三级缓存，这点需要注意。12345678[root@MiWiFi-R4A-srv stream-scaling]# ./stream-scaling ...Function Best Rate MB/s Avg time Min time Max timeCopy: 30856.3 0.013801 0.013763 0.013844Scale: 22146.1 0.019212 0.019176 0.019277Add: 23729.2 0.026920 0.026845 0.027144Triad: 23754.1 0.026879 0.026817 0.026973...]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>MEM</tag>
        <tag>stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3DXPoint与Optane学习笔记整理]]></title>
    <url>%2F2019%2F04%2F3DXPoint%E4%B8%8EOptane%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言与时俱进、终身学习。本文是针对公众号《企业存储技术》里面3DXPoint、Optane SSD相关文章的学习总结。文章涉及到的产品有 Optane SSD 900P Optane SSD P4800X 暂时不涉及Optane Persistent Memory（AEP）。 笔记部分 Intel已经研究PCM 45年了！3DXPoint其实就是3D的PCM。 Intel CPU的内存控制器，将直接支持基于PCM的DIMM内存条（Far Memory，也就是3D XPoint），并保持在每个通道上同时支持DDR DRAM（Near Memory）的能力。 HDD的10ms大致代表7200转硬盘，使用NAND闪存的SAS/SATA SSD超过100µs，换成NVMe接口降低到100µs以内，3D XPoint大约在10µs左右。 性能预览：不再依赖于并发/队列深度，在很低的队列深度下就能达到接近峰值性能。 3D Xpoint除了非易失特性之外，主要的优点就是可以比DRAM内存做得更大，并且单位容量更便宜。 保守（真实）的NAND闪存。以ONFI 2.x 接口的Micron 512Gb MLC为例，物理块大小8800KB，页面即最小I/O单位16KB，读延时115μs，页面编程即写延时1600μs（1.6ms），而块擦除需要3ms。 闪存如果要重复写入需要先擦除，即P/E Cycle的过程。可以说闪存控制器和SSD厂商做了大量工作，我们才能用到实际读/写延时100μs左右的产品，至于比这个低的，我只能说DRAM缓存了。 Intel SSD标称的20μs延时是顺序读写，随机访问的读/写延时为115/25μs，显然写I/O还是进入了DRAM缓存里。 除了平均延迟以外，还有一个重要概念叫QoS延迟，它代表在一定百分比范围内的响应时间最大值，反映了延时的稳定性，非常影响用户体验。例如QoS延时举例，4KB（KiB，4096字节）块大小、队列深度（QD）16、99.999%的读/写IO延时不超过150/200μs。 Intel P3700在99.99% QoS范围、QD=1的4KB随机读延时为4ms，是Optane P4800X的60μs的接近70倍，而且后者的QoS等级还要更高。所以Intel以前强调3D XPoint介质的低队列深度读性能优势不是没有道理的。 内存的基本操作单位是64bytes，现在发布的Optane SSD也像NAND闪存那样是块级设备，本身不能以字节方式寻址（未来还会有DIMM形态的3D XPoint）。Intel Memory Drive Technology要解决的就是这个问题，而该软件技术来自于一家合作伙伴ScaleMP。 3D XPoint Memory可能不是普通的相变（结晶/非结晶态转换）或者电阻式存储介质，不像闪存要有一个P/E Cycle，即改写数据时不用先进行擦除操作了。这样也就不需要垃圾回收（GC），理论上编程的长度单位可以不受诸如页面、块之类的限制。那我为啥还给了个“写放大”的评价 由于3D XPoint能就地改写，不像NAND闪存SSD那样需要OP来做垃圾回收，那么就是用于ECC、Firmware和其它维护操作。 维护操作，显然还是需要有的。虽然不用GC了，但磨损平衡还要做，包括数据完整性扫描、搬移这些后台操作应该会有，以及像NAND闪存那样预留一些空间替换损坏的存储单元。 Optane P4800X上没有单独的缓存芯片，也没看到有大容量电容。而据了解它实际上仍然具备Power Loss Imminent（PLI）技术，需要保护的临时buffer数据量很小而已。元数据映射表不再放在单独的DRAM中，因为3D XPoint Memory本身就是一种非易失性内存介质，而且它的速度足够快。 Optane P4800X当队列深度=1延时小于10μs，QD=16也仅上升到20μs。可以看出PCIe接口在这里的限制，如果未来做成DIMM形态插在内存通道上，与闪存的差距预计还会加大。 OptaneP4800X 375GB可能是7通道设计。根据QD=16基本达到峰值的测试数据来看，3D XPoint Memory的实际并发效果比NAND闪存要好。 P3700的随机写一开始可达40万IOPS，当OP（超量分配）空间用满后台触发GC（垃圾回收）滑落到10万出头然后逐渐恢复到17万稳定值。 下一代服务器对NVMe SSD数量支持的增加，未来高性能的存储应用负载，最终分摊到每节点上单一SSD的IO队列深度仍然不见得会很高。以P3700为代表的NAND闪存盘，许多应用中其最大IOPS可能无法充分发挥。Optane从根本上克服了NAND Flash的天生缺陷，利用更低和更稳定的时延，即便在很低的并发度下也能达到系统吞吐量的顶峰，天生适用于OLTP类业务。 使用新型3D XPoint Memory非易失存储器介质的OptaneP4800X，相对于传统NAND闪存SSD价格不菲。以目前的情况，我们认为它更适合放置数据库日志，或者用于高速存储系统（如全闪存阵列/Server SAN）的大容量缓存。 与之前Oracle测试中的情况类似，MySQL SysBench也是在数据库Cache命中率调低后，才能将SSD存储的差距放大。如今瓶颈更多在于CPU和软件本身，“软件的适配还跟不上硬件的发展”。 SPDK在低并发/队列深度下的优势相当明显。无论IOPS还是延时，当队列深度1-4时SPDK的领先都在一倍以上，此时OptaneP4800X最低测出了6.49μs随机读延时的表现。 当队列深度达到16之后，测试瓶颈开始显现在SSD硬件本身上面，SPDK和内核态没有明显差别了。也就是说，polling轮询相对于传统的中断I/O模式，3D XPoint Memory在低队列深度下的性能优势能够更好地发挥出来。 随机写测试的情况类似，Optane P4800X在队列深度=1时延迟低至8μs。写和读有一点不同的是，当并发/队列深度达到16或以上，SPDK下的IOPS超过55万，比官方标称的50万还要高。与之对应的是，这时延迟也要比内核态低。 Intel P3700随机读在SPDK下也有一些提高，但远不及Optane P4800X明显。究其原因，应该是传统NAND闪存SSD在低队列深度下的自身瓶颈所致。 随机写，由于P3700上有DRAM Cache的帮助，SPDK带来的优势比读大了许多。同时也出现了和Optane P4800X类似的情况——最大写IOPS超出规格标称值，达到20.8万。 性能和资源利用是一回事，而SPDK在应用中的普及则是另外一回事。毕竟传统文件系统、应用都是跟Kernel块设备打交道，要牵涉到开发习惯等方面的变化。 随机写QoS延时，由于是单队列，绝大多数I/O都能在SSD的写缓存中先合并，所以如果只看平均延时，FIO测试的结果会看出两款卡相差不多。而到了高等级QoS特别是99.999%时，Optane才显出10倍以上的优势。 高并发/QD下的的随机写QoS延时，可以说是Optane P4800X最擅长的地方。3D XPoint Memory介质可以直接写入，没有NAND闪存P/E Cycle（编程/擦除周期）产生的写放大，也不需要垃圾回收。所以我们看到P4800X的QD=16 99.999%随机写延时标称值为200μs，我实测1小时得到141μs，而P3700则高达8ms了。 我们有时会看到一些消费级SSD的写IOPS指标，比不少企业级SSD还要高。这里面有容易被忽视的一点——闪存SSD如果限制测试LBA范围，其随机写性能通常比全盘测试高许多。于是在一些盘的规格资料小字中就可能看到“8GB Span”的备注。由于3D XPoint Memory属于类似PRAM相变内存的介质，不需要GC垃圾回收，所以8GB Span和100% Span性能完全一致。 应用程序角度 对于单线程的同步I/O的应用，高时延单/多通道链路带来的是反应慢、吞吐量低的极差体验。也就是说，当你打开一个网页，不但浏览器状态栏半天才会从“正在连接”变到“正在接收数据”，而且“正在接收数据”这个状态也会持续很长时间，网页上的内容慢腾腾的逐步显示出来。 对于多个或者多线程同步I/O应用并发访问场景，高时延单通道链路带来的是更慢上加慢让人无法忍受甚至最终让应用I/O超时引发宕机的灾难性体验。因为多线程会争抢唯一的一个通道，导致整体访问时延中不得不增加I/O的等待时延这个分量，也就是等待其他线程让出通道，自己被调度上通道。 对于多个或者多线程同步I/O应用并发访问场景，高时延多通道链路带来的是反应慢、吞吐量低的极差体验。但是只要线程数量没有超过并发通道数，并且可以保证每个线程独占一个通道，那么多个线程并发之后，每个线程的体验是均等的，并不会像#2情况那样严重。 对于单线程异步I/O应用，高时延单通道链路，体验与#2一致。 对于单线程异步I/O应用，高时延多通道链路，体验较好，因为其可以利用其其他多个通道，从而可以提升整体吞吐量。 时延越低，越有利于单线程同步I/O应用的性能，并发度越高，越有利于异步I/O应用。 OLTP业务对IO的要求是时延和吞吐量兼具，而OLAP场景一般只要求吞吐量。同时，OLTP类业务发出同步模式的IO的比例远高于OLAP类业务，因为实时性场景下，很多时候必须一步一步的来，比如点击购买按钮，付款后，才能走下一步，没有任何电商为了实现批量下发IO获得高吞吐量而在你点击购买按钮之后不等你付款就直接让商家打包包裹去了。同步IO是最难优化的IO场景。一般都是OLTP类业务会遇到性能问题，就是因为其对时延有要求，自己还时不时就发送同步IO。 OLTP类应用对时延和并发度都要求比较高，但是对时延更加敏感。OLTP的业务特征决定了其I/O中具有大量比例的同步I/O，而且有些批量异步I/O整体上可能取决于某个同步I/O，也就是只有某个I/O执行完毕，后续才会发出批量异步I/O，这种关联关系隐含的更加深，不容易被察觉。]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>Optane</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试16G的玩具傲腾Optane性能]]></title>
    <url>%2F2019%2F04%2F%E6%B5%8B%E8%AF%9516G%E7%9A%84%E7%8E%A9%E5%85%B7%E5%82%B2%E8%85%BEOptane%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[背景逛淘宝发现全新拆机件Optane Memory 16G非常便宜，只要50来块钱。 好像是联想笔记本的拆机件，原本出厂是在Windows系统里作为HDD cache使用。我猜是因为它占用了一个M.2的的插槽，很多用户觉得鸡肋，于是扔了Optane Memory 16G，换成大容量的M.2 NVMe SSD，所以有大量的16G拆机件流入了淘宝。 在存储分层中，NVM是介于内存和SSD之间的一层，填补内存和SSD的延迟鸿沟。Optane Memory使用3D XPoint存储介质，它作为NVM的一种，据悉可以在低并发下达到很高的iops，且延时极低。企业级的Optane SSD非常昂贵，单位GB成本是SSD的五倍。 比较好奇，还没有玩过3D XPoint，所以搞两个来玩玩。这个16G的基本上是个玩具，所以随便测测，仅用于探索一些3D XPoint介质的特性。 环境下面是我的台式机环境：123456789101112131415[root@MiWiFi-R4A-srv ~]# perl hwconfig hwconfig: warning: cpu0/cpufreq/scaling_governor should be &apos;ondemand&apos;, not &apos;powersave&apos;; see http://tiny.corp.hwconfig.com/xNR1csSummary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.3GB / 16GB 3000MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.3GB / 16GB 3000MT/s DDR4 == 2 x 8GBDisk: sda (scsi1): 100GB (11%) JBOD == 1 x 100GB INTEL-SSDSA2BZ100G3Disk: sdb: 100GB JBOD == 1 x 100GB INTEL-SSDSA2BZ100G3Disk-Control: ahci0: Intel 200 Series PCH SATA controller [AHCI mode]Network: 00:1f.6 (e1000e0): Intel Ethernet Connection (2) I219-VNetwork: 02:00.0 (igb0): Intel I211 GigabitNetwork: 03:00.0 (iwlwifi0): Intel Dual Band Wireless-AC 3168NGW [Stone Peak]OS: Fedora 30 (Thirty), Linux 5.0.7-300.fc30.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R4A-srv nvme0n1就是Optane Memory 16G，在Linux里直接使用nvme驱动识别成为了块设备。这和其它的NVME SSD没有什么不同。1234[root@MiWiFi-R4A-srv ~]# nvme listNode SN Model Namespace Usage Format FW Rev ---------------- -------------------- ---------------------------------------- --------- -------------------------- ---------------- --------/dev/nvme0n1 PHBT82620BLV016N INTEL MEMPEK1J016GAL 1 14.40 GB / 14.40 GB 512 B + 0 B K4110420 性能测试在以前，我们会自己写shell脚本调用fio来测试SSD的各维度的性能。这次我们直接用现成的工具好了。TKperf可以自己生成图形报告，非常好用，网址如下： https://www.thomas-krenn.com/de/wiki/TKperf https://github.com/thomas-krenn/TKperf 执行的时候，会调用format命令，在我的系统里，会卡住。可能是optane这个SSD对format指令兼容性问题。这条命令是擦除所有数据，不擦除也是一样测试，所以我加了个echo，取消这条命令执行，直接改成打印。1234nvme format /dev/nvme0n1 -s=1 -l=0TKperf/build/lib/perfTest/Devices.py:out = subprocess.Popen(['echo', 'nvme', 'format', self.getDevPath(), '-s=1', lbaf_opt],stdout=subprocess.PIPE,stderr=subprocess.PIPE) 现在开始执行测试，这里是1个numjobs，1个iodepth的场景，TKperf的优点在于它会自动给你设置不同的blocksize还有读写比例。所以我们覆盖不同的场景，只需要调整numjobs和iodepth即可：1nohup tkperf ssd optane16g /dev/nvme0n1 -ft -nj 1 -iod 1 -rfb -i nvme 1&gt;runTest.out 2&gt;runTest.err &amp; 执行如下两条命令即可生产报告：12tkperf ssd optane16g none -xmlrst2pdf optane16g.rst optane16g.pdf 测试结果具体的测试结果，查看tkperf的pdf报告即可。这里我们只分析optane最大的几个特点： psync单并发下，4k随机读的性能是10us。普通的nvme ssd大约是60us。 psync单并发下，512b随机读性能是5us，延时小于4k，说明介质操作的粒度更低。 作为一个单颗粒封装，只有16G的SSD，极限能达到140000的iops，150MB/s写，600MB/s的读。任何16G的nand介质SSD绝对达不到这个水准。 optane没有DRAM cache，不需要超级电容来做掉电保护。 总结学习存储测试相关知识，最好的材料就是SNIA组织的文档了。 https://www.snia.org/forums/sssi/knowledge/articles-presentations PTS是SNIA组织的测试标准，里面介绍了SSD测试的一般用例。当你需要为公司引入SSD部件时，参考这个文档的测试用例项。 http://www.snia.org/tech_activities/standards/curr_standards/pts https://www.snia.org/sites/default/files/technical_work/PTS/SSS_PTS_2.0.1.pdf 作为只有16G的optane玩具，IOPS并发性能和10us的4k读延时让人印象深刻。后面有机会再玩正儿八经的Intel Optane DC SSD。]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>Optane</tag>
        <tag>tkperf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU的缓存失效和分支预测的例子]]></title>
    <url>%2F2019%2F04%2FCPU%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E5%92%8C%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B%E7%9A%84%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[前言最近学习CPU关于cache-miss和branch-miss的相关知识，从网上找了两个案例来验证。 计算机体系局部性原理：它更倾向于引用最近引用过的数据项（时间局部性），或者这个数据周围的数据（空间局部性）。 硬件层，缓存，分支预测。 操作系统：缓存，预读 应用层：Cache、CDN cache-miss这个案例里，一维数组在内存是连续空间。当二维数组按行操作时，CPU缓存能命中，不用反复去内存里读取数据。但是按列操作时，由于每行数组数据量较大，会击穿CPU缓存，每次操作都需要重新去内存里读取一行。123456789101112131415161718192021222324#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; int main(int argc, char *argv[])&#123; int a[1000][1000]; if(argc == 1) &#123; int i,j; for(i = 0; i &lt; 1000; ++i) &#123; for(j = 0; j &lt; 1000; ++j) &#123; a[i][j] = 0; &#125; &#125; &#125; else if (argc == 2) &#123; int i,j; for(i = 0; i &lt; 1000; ++i) &#123; for(j = 0; j &lt; 1000; ++j) &#123; a[j][i] = 0; &#125; &#125; &#125; return 0;&#125; 使用perf来跟踪cache miss情况，当传入参数时，是按列操作。123456789101112131415[root@MiWiFi-R4A-srv ctest]# perf stat -e L1-dcache-load-misses ./test Performance counter stats for './test': 88,690 L1-dcache-load-misses 0.003754295 seconds time elapsed[root@MiWiFi-R4A-srv ctest]# perf stat -e L1-dcache-load-misses ./test cachemiss Performance counter stats for './test cachemiss': 1,079,688 L1-dcache-load-misses 0.002821310 seconds time elapsed branch-miss这个案例里，先排序再比较，能提升分支预测准确性，大幅度提升性能。12345678910111213141516171819202122232425262728293031323334#include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main()&#123; // 产生随机数数组，随机数在0-255之间 const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; // 关键：加上这句后程序运行明显会更快！ //std::sort(data, data + arraySize); // 测试 clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i) &#123; for (unsigned c = 0; c &lt; arraySize; ++c) &#123; if (data[c] &gt;= 128) //条件分支 sum += data[c]; &#125; &#125; double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; "sum = " &lt;&lt; sum &lt;&lt; std::endl;&#125; 使用perf来查看分支预测成功率，可以看到排序后性能提升3倍以上。123456789101112131415161718192021222324252627282930313233[root@MiWiFi-R4A-srv ctest]# perf stat ./testb18.31sum = 314931600000 Performance counter stats for './testb': 18315.489297 task-clock (msec) # 1.000 CPUs utilized 11 context-switches # 0.001 K/sec 4 cpu-migrations # 0.000 K/sec 369 page-faults # 0.020 K/sec 72,874,694,304 cycles # 3.979 GHz 29,585,265,782 instructions # 0.41 insn per cycle 6,565,177,618 branches # 358.449 M/sec 1,603,125,199 branch-misses # 24.42% of all branches 18.316115315 seconds time elapsed[root@MiWiFi-R4A-srv ctest]# perf stat ./testc5.88sum = 314931600000 Performance counter stats for './testc': 5888.781567 task-clock (msec) # 1.000 CPUs utilized 8 context-switches # 0.001 K/sec 4 cpu-migrations # 0.001 K/sec 369 page-faults # 0.063 K/sec 23,351,472,182 cycles # 3.965 GHz 29,556,013,915 instructions # 1.27 insn per cycle 6,559,924,468 branches # 1113.970 M/sec 486,175 branch-misses # 0.01% of all branches 5.889261494 seconds time elapsed 查看CPU cache结构可以使用lstopo-no-graphics，它属于hwloc这个包。12345678910111213141516171819202122232425262728[root@MiWiFi-R4A-srv ctest]# lstopo-no-graphicsMachine (31GB) Package L#0 + L3 L#0 (9216KB) L2 L#0 (256KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0 + PU L#0 (P#0) L2 L#1 (256KB) + L1d L#1 (32KB) + L1i L#1 (32KB) + Core L#1 + PU L#1 (P#1) L2 L#2 (256KB) + L1d L#2 (32KB) + L1i L#2 (32KB) + Core L#2 + PU L#2 (P#2) L2 L#3 (256KB) + L1d L#3 (32KB) + L1i L#3 (32KB) + Core L#3 + PU L#3 (P#3) L2 L#4 (256KB) + L1d L#4 (32KB) + L1i L#4 (32KB) + Core L#4 + PU L#4 (P#4) L2 L#5 (256KB) + L1d L#5 (32KB) + L1i L#5 (32KB) + Core L#5 + PU L#5 (P#5) Misc(MemoryModule) Misc(MemoryModule) HostBridge L#0 PCI 8086:3e92 GPU L#0 "card0" GPU L#1 "renderD128" GPU L#2 "controlD64" PCI 8086:a282 Block(Disk) L#3 "sda" Block(Disk) L#4 "sdb" Block(Disk) L#5 "sdc" PCIBridge PCI 8086:1539 Net L#6 "enp2s0" PCIBridge PCI 8086:24fb Net L#7 "wlp3s0" PCI 8086:15b8 Net L#8 "enp0s31f6"]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>CPU</tag>
        <tag>性能监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全链路分析数据落盘机制-文件系统层及块设备层]]></title>
    <url>%2F2019%2F04%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E5%8F%8A%E5%9D%97%E8%AE%BE%E5%A4%87%E5%B1%82%2F</url>
    <content type="text"><![CDATA[前言本文从文件系统和块设备层介绍Linux内核关于数据落盘的机制。 总结之前的内容sync、fsync、fdatasync 和 fflush fopen(3)属于C标准库的函数，以数据流（stream）方式打开文件，fwrite(3)是写入应用层缓冲（glibc实现），不保证落盘，但有一个叫fflush(3)的函数好像有用？实际上fflush也属于C标准库，它仅仅是把应用层缓冲写入内核缓冲（pagecache），所以fflush和数据落盘也不沾边。 sync(2)、fsync(2)、fdatasync(2)属于系统调用，应用程序调用时，内核会把内核缓冲（pagecache）数据写入磁盘。 open属于系统调用，以文件描述符打开文件，使用O_DIRECT标志位来禁用pagecache。使用O_SYNC，O_DSYNC来达到每次write都实现fsync和fdatasync的效果，否则fsync和fdatasync只能作用一次。 fsync(2)、fdatasync(2)的区别仅仅是，fdatasync不保证文件系统元数据落盘，性能更好，但有安全风险。 这张图表明了这些层次关系，Summary of IO buffering： DirectIO这张图显示了DirectIO的路径： 数据拷贝，从磁盘到Page Cache算第一次的话，从Page Cache到用户态buffer就是第二次。 mmap(2)直接把Page Cache映射到了用户态的地址空间里了，所以mmap(2)的方式读文件是没有第二次拷贝过程。 用户态和块IO层对接，直接放弃Page Cache，从磁盘直接和用户态拷贝数据。通过DMA的方式。 mmap(2)和Direct IO均有数据按页对齐的要求，Direct IO还限制读写必须是底层存储设备块大小的整数倍。 文件系统层sys_fsync/sys_datasync123456789101112131415161718---&gt; do_fsync ---&gt; vfs_fsync ---&gt; vfs_fsync_range ---&gt; mark_inode_dirty_sync | ---&gt; ext4_dirty_inode | | ---&gt; ext4_journal_start | | ---&gt; ext4_mark_inode_dirty | | ---&gt; ext4_journal_stop | ---&gt; inode_io_list_move_locked | ---&gt; wb_wakeup_delayed ---&gt; ext4_sync_file ---&gt; filemap_write_and_wait_range | ---&gt; __filemap_fdatawrite_range | ---&gt; do_writepages | ---&gt; ext4_writepages | ---&gt; filemap_fdatawait_range ---&gt; jbd2_complete_transaction ---&gt; blkdev_issue_flush fs/ext4/fsync.c123456789ext4_sync_file: if (journal-&gt;j_flags &amp; JBD2_BARRIER &amp;&amp; !jbd2_trans_will_send_data_barrier(journal, commit_tid)) needs_barrier = true; ret = jbd2_complete_transaction(journal, commit_tid); if (needs_barrier) &#123; err = blkdev_issue_flush(inode-&gt;i_sb-&gt;s_bdev, GFP_KERNEL, NULL); if (!ret) ret = err; 块设备层linux-src/block/blk-flush.c12blkdev_issue_flush ---&gt;submit_bio(WRITE_FLUSH, bio); linux-src/include/linux/fs.h1#define WRITE_FLUSH (WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FLUSH) linux-src/include/linux/blk_types.h123enum rq_flag_bits &#123; __REQ_FUA, /* forced unit access */ __REQ_FLUSH, /* request for cache flush */ 这两个标致位，会触发驱动发出刷盘命令 总结有以下几点需要注意，个人理解： O_DIRECT只是让用户态数据通过DMA直接写进磁盘，跳过Pagecache，虽然O_DIRECT已经是同步IO了，但是仍然不保证落盘。需要O_SYNC配合使用，刷新数据和元数据， 由于磁盘存在cache，O_DIRECT不能保证落盘有两方面原因，1.它不保证元数据落盘。2.它不像O_SYNC那样下发“刷盘”命令，把磁盘cache的数据刷到碟片上。 由于O_DIRECT已经是同步IO了，所以O_DIRECT配合O_DSYNC使用是没有什么意义的，因为元数据没有保障落盘。 文件系统有个barrier参数，当磁盘没有掉电保护时，需要这个参数，这样会带“刷盘”命令到磁盘，等待磁盘cache数据写入碟片，以此来保证文件系统日志先落盘，数据后落盘。当磁盘有掉电保护时（例如企业级SSD），可以使用nobarrier参数，此时性能更好，也不会下发刷盘命令。]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>刷盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全链路分析数据落盘机制-基础知识及应用层]]></title>
    <url>%2F2019%2F04%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%8F%8A%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[前言本文介绍一些Linux系统基础知识，用于更好地理解内核和IO链路。此外，本文也介绍一些应用层来保障数据落盘的机制，例如fsync，fdatasync等。 库函数和系统调用介绍 库函数是为了方便人们编写应用程序。库函数（library function），是由用户或组织自己开发的，具有一定功能的函数集合，一般具有较好平台移植性，通过库文件（静态库或动态库）向程序员提供功能性调用。程序员无需关心平台差异，由库来屏蔽平台差异性。 系统调用是为了方便应用使用操作系统的接口。系统调用（system call），指运行在用户空间的应用程序向操作系统内核请求某些服务的调用过程。 系统调用提供了用户程序与操作系统之间的接口。一般来说，系统调用都在内核态执行。由于系统调用不考虑平台差异性，由内核直接提供，因而移植性较差（几乎无移植性）。 常见库函数printf，scanf，fopen，fclose，fgetc，fgets，fprintf，fsacnf，fputc，calloc，free，malloc，realloc，strcat，strchr，strcmp，strcpy，strlen，strstr等，需要包含stdio.h，string.h，alloc.h，stdlib.h等头文件。 常见系统调用open, close, read, write, ioctl，fork，clone，exit，getpid，access，chdir，chmod，stat，brk，mmap等，需要包含unistd.h等头文件。 区别 所有 C 函数库是相同的，而各个操作系统的系统调用是不同的。 函数库调用是调用函数库中的一个程序，而系统调用是调用系统内核的服务。 函数库调用是与用户程序相联系，而系统调用是操作系统的一个进入点 函数库调用是在用户地址空间执行，而系统调用是在内核地址空间执行 函数库调用的运行时间属于「用户」时间，而系统调用的运行时间属于「系统」时间 函数库调用属于过程调用，开销较小，而系统调用需要切换到内核上下文环境然后切换回来，开销较大 在C函数库libc中大约 300 个程序，在 UNIX 中大约有 90 个系统调用 函数库典型的 C 函数：system, fprintf, malloc，而典型的系统调用：chdir, fork, write, brk 查询系统调用属于man的第二部分，库函数属于man的第三部分。1234man man2 System calls (functions provided by the kernel)3 Library calls (functions within program libraries)man 2 open 库函数：man 3 fopen 系统调用：man 2 open 以c语言库函数举例，glibc库函数头文件属于glibc-headers包：1234[root@MiWiFi-R1CM-srv ~]# rpm -qf /usr/include/stdio.h glibc-headers-2.17-260.el7_6.3.x86_64[root@MiWiFi-R1CM-srv ~]# rpm -qf /usr/include/unistd.hglibc-headers-2.17-260.el7_6.3.x86_64 系统调用头文件属于kernel-headers包：12[root@MiWiFi-R1CM-srv ~]# rpm -qf /usr/include/asm/unistd_64.h kernel-headers-3.10.0-957.5.1.el7.x86_64 对应跟踪工具，ltrace和strace12ltrace - A library call tracerstrace - trace system calls and signals 应用层的刷盘pythonpython3.3以上使用os.sync。1234os.sync()Force write of everything to disk.Availability: Unix.New in version 3.3. python2需要引用外部。1234&gt;&gt;&gt; import ctypes&gt;&gt;&gt; libc = ctypes.CDLL("libc.so.6")&gt;&gt;&gt; libc.sync()0 JavaJDK中有三种方式可以强制文件数据落盘： 调用 FileDescriptor#sync函数 12调用IO_Sync来执行数据同步IO_Sync在UNIX系统上的定义就是 fsync 调用 FileChannel#force函数 12FileChannel#force 调用 FileDispatcher#force通过 metaData 参数来区分调用 fsync 和 fdatasync 使用 RandomAccessFile 以 rws 或者 rwd 模式打开文件 1234“rws” 还要求对文件的内容或元数据的每个更新都同步写入到底层存储设备。“rwd” 还要求对文件内容的每个更新都同步写入到底层存储设备。rws 模式会在 open 文件时传入 O_SYNC 标志位。 rwd 模式会在 open 文件时传入 O_DSYNC 标志位。 C语言 UNIX系统提供了三个系统调用来执行刷新内核缓冲区： sync ， fsync ， fdatasync 。 sync函数将所有修改过的块缓冲区落盘再返回。 fsync对指定文件生效，传输内核缓冲区中这个文件的数据落盘再返回。包含数据与文件系统元数据。 fdatasync仅刷新数据，不刷新文件系统元数据。 除了上面三个系统调用， open 系统调用在打开文件时，可以设置和同步相关的标志位： O_SYNC 和 O_DSYNC 。 设置 O_SYNC 的效果相当于是每次 write 后自动调用 fsync 。 设置 O_DSYNC 的效果相当于是每次 write 后自动调用 fdatasync 。 总结：从Python和Java可以看出来，这些高级语言，为了保证数据落盘，绕来绕去都回到C语言库的fsync和fdatasync。接下来的文章，我们在文件系统层和块设备层进一步分析。]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>刷盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux性能优化实战笔记-CPU篇]]></title>
    <url>%2F2019%2F04%2FLinux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-CPU%E7%AF%87%2F</url>
    <content type="text"><![CDATA[前言2013年，我因为工作需要开始进入Linux性能分析、优化及Debug领域。 2019年，恰逢《极客时间》的APP有了《Linux性能优化实战》课程，我也参与订阅学习，这篇文章便是学习笔记。这个课程非常不错，链接如下：https://time.geekbang.org/column/intro/140 当然，在这个领域，Netflix的Brendan D. Gregg大神的博客和PPT仍然是最优秀的学习材料，我在后面也会分享关于他的学习笔记。 CPU基础 CPU 其实也不是单纯的一块，它包括三个部分，运算单元、数据单元和控制单元。 运算单元只管算，例如做加法、做位移等等。但是，它不知道应该算哪些数据，运算结果应该放在哪里。 数据单元包括 CPU 内部的缓存和寄存器组，空间很小，但是速度飞快，可以暂时存放数据和运算结果。 控制单元是一个统一的指挥中心，它可以获得下一条指令，然后执行这条指令。这个指令会指导运算单元取出数据单元中的某几个数据，计算出个结果，然后放在数据单元的某个地方。 第一周 00-081 性能分析，其实就是找出应用或系统的瓶颈，并设法去避免或者缓解它们，从而更高效地利用系统资源处理更多的请求。这包含了一系列的步骤，比如下面这六个步骤。 选择指标评估应用程序和系统的性能； 为应用程序和系统设置性能目标； 进行性能基准测试； 性能分析定位瓶颈； 优化系统和应用程序； 性能监控和告警。 2 平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和CPU使用率并没有直接关系。 所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态（Running或Runnable）的进程。 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的IO响应，也就是我们在ps命令中看到的D状态（UninterruptibleSleep，也称为DiskSleep）的进程。 比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。 平均负载高有可能是CPU密集型进程导致的； 平均负载高并不一定代表CPU使用率高，还有可能是IO更繁忙了； 当发现负载高的时候，你可以使用mpstat、pidstat等工具，辅助分析负载的来源。 3 Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。 而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）。 CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。 4 CPU和寄存器资料：Intel® 64 and IA-32 Architectures Software Developer Manuals 5 CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 6 操作系统管理的任务可以分为进程、线程、硬件中断。所以，根据任务的不同，CPU的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。 7 进程上下文切换，Linux按照特权级别，分为内核空间和用户空间，对应CPU的Ring0和Ring3，参考Protection ring 内核空间（Ring 0）具有最高权限，可以直接访问所有资源； 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。 8 也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。 从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。 9 系统调用的过程发生上下文切换，CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。 不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的： 进程上下文切换，是指从一个进程切换到另一个进程运行。 而系统调用过程中一直是同一个进程在运行。 所以，系统调用过程通常称为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。 10 进程上下文切换跟系统调用区别： 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。 因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。 另外，Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。 11 什么时候会切换进程上下文？ 进程切换时才需要切换上下文，换句话说，只有在进程调度的时候，才需要切换上下文。Linux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选择最需要 CPU 的进程，也就是优先级最高和等待 CPU 时间最长的进程来运行。 12 发生进程调度的场景，他们就是出现上下文切换性能问题的原因。 其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。 最后一个，发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。 13 查看进程被切换的情况，主动切换次数和被动切换次数。123[root@MiWiFi-R1CM-srv ~]# cat /proc/5800/status | grep switchesvoluntary_ctxt_switches: 239nonvoluntary_ctxt_switches: 70 14 线程上下文切换线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。线程的上下文切换其实就可以分为两种情况： 第一种，前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 第二种，前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。 15 中断的上下文切换为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。 15 用systemtap跟踪中断，这里操作磁盘一次，通过/proc/interrupts和lspci，可以知道中断号123是南桥PCH（dd操作），129是网卡（ssh数据）。123456[root@MiWiFi-R1CM-srv ~]# stap -e &apos;global irq; probe kernel.trace(&quot;irq_handler_entry&quot;) &#123;irq[$irq]&lt;&lt;&lt;1&#125;&apos; -c &apos;dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct&apos;记录了1+0 的读入记录了1+0 的写出4096字节(4.1 kB)已复制，0.000219332 秒，18.7 MB/秒irq[123] @count=29 @min=1 @max=1 @sum=29 @avg=1irq[129] @count=1 @min=1 @max=1 @sum=1 @avg=1 16 除了vmstat以外，用pidstat看每个进程的上下文切换情况12345678# 每隔 5 秒输出 1 组数据$ pidstat -w 5Linux 4.15.0 (ubuntu) 09/23/18 _x86_64_ (2 CPU)08:18:26 UID PID cswch/s nvcswch/s Command08:18:31 0 1 0.20 0.00 systemd08:18:31 0 8 5.40 0.00 rcu_sched... 17 一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数，另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。 而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。 18 pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。1234567891011# 每隔 1 秒输出一组数据（需要 Ctrl+C 才结束）# -wt 参数表示输出线程的上下文切换指标$ pidstat -wt 108:14:05 UID TGID TID cswch/s nvcswch/s Command...08:14:05 0 10551 - 6.00 0.00 sysbench08:14:05 0 - 10551 6.00 0.00 |__sysbench08:14:05 0 - 10552 18911.00 103740.00 |__sysbench08:14:05 0 - 10553 18915.00 100955.00 |__sysbench08:14:05 0 - 10554 18827.00 103954.00 |__sysbench... 19 当超过cpu处理能力时，会造成中断升高，这是因为过多任务的调度问题。使用watch命令，变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）。123456# -d 参数表示高亮显示变化的区域$ watch -d cat /proc/interrupts CPU0 CPU1...RES: 2450431 5279697 Rescheduling interrupts... 20 每秒上下文切换多少次才算正常呢？ 这个数值其实取决于系统本身的 CPU 性能。在我看来，如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。 这时，你还需要根据上下文切换的类型，再做具体分析。比方说： 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题； 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈； 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。 21 Linux 作为一个多任务操作系统，将每个 CPU 的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。12[root@MiWiFi-R1CM-srv ~]# grep &apos;CONFIG_HZ=&apos; /boot/config-$(uname -r)CONFIG_HZ=1000 22 碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。 对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。 23 用我们最熟悉的 ps 或者 top ，可以查看进程的状态，这些状态包括运行（R）、空闲（I）、不可中断睡眠（D）、可中断睡眠（S）、僵尸（Z）以及暂停（T）等。 其中，不可中断状态和僵尸状态，是我们今天学习的重点。 不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 I/O 性能问题。 僵尸进程表示进程已经退出，但它的父进程还没有回收子进程占用的资源。短暂的僵尸状态我们通常不必理会，但进程长时间处于僵尸状态，就应该注意了，可能有应用程序没有正常处理子进程的退出。 24 中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。 由于中断处理程序会打断其他进程的运行，所以，为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。如果中断本身要做的事情不多，那么处理起来也不会有太大问题；但如果中断要处理的事情很多，中断服务程序就有可能要运行很长时间。 特别是，中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失。 25 为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部： 上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 26 中断上半部分和下半部分总结 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行； 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 /proc/softirqs 提供了软中断的运行情况； /proc/interrupts 提供了硬中断的运行情况。 27 系统层面的 CPU 优化方法也有不少，列举了最常见的一些方法。 CPU 绑定：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。 CPU 独占：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。 优先级调整：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。优先级的数值含义前面我们提到过，忘了的话及时复习一下。在这里，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理。 为进程设置资源限制：使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源。 NUMA（Non-Uniform Memory Access）优化：支持 NUMA 的处理器会被划分为多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。 中断负载均衡：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上。]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>CPU</tag>
        <tag>性能监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全链路分析数据落盘机制-跟踪sync命令]]></title>
    <url>%2F2019%2F03%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6-%E8%B7%9F%E8%B8%AAsync%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前言本文面向初学者，用sync这条命令来介绍刷盘经历了哪些过程，以及sync命令如何保证数据落盘。本文可以了解一些跟踪系统调用的知识。 sync函数通过man sync可以看到，sync - flush file system buffersForce changed blocks to disk, update the super block.info命令还可以看到更多介绍：1234567891011info coreutils &apos;sync invocation&apos;&apos;sync&apos; writes any data buffered in memory out to disk. This can include(but is not limited to) modified superblocks, modified inodes, anddelayed reads and writes. This must be implemented by the kernel; The&apos;sync&apos; program does nothing but exercise the &apos;sync&apos; system call. The kernel keeps data in memory to avoid doing (relatively slow) diskreads and writes. This improves performance, but if the computercrashes, data may be lost or the file system corrupted as a result. The&apos;sync&apos; command ensures everything in memory is written to disk. sync命令属于coreutils这个rpm包，coreutils-8.22/src/sync.c。打开源码，发现没有实际内容，只有最后的sync()函数有意义。接下来查看sync()函数的说明，使用man 2 sync。1234567NAMEsync, syncfs - commit buffer cache to disk#include &lt;unistd.h&gt;DESCRIPTION sync() causes all buffered modifications to file metadata and data to be written to the underlying file systems. 可以看到/usr/include/unistd.h，这个文件属于glibc，属于glibc-headers这个rpm包，12/* Make all changes done to all files actually appear on disk. */extern void sync (void) __THROW; glibc的unistd.h里sync函数，是对sync系统调用的一个包装，因为刷盘是一个与内核强相关的底层操作，glibc作为标准C库，仅靠自身是无法实现这些功能的，要借助内核来实现。 下面背景知识和概念需要了解： libc实际上是一个泛指。凡是符合实现了C标准规定的内容，都是一种libc。 glibc是GNU组织对libc的一种实现。它是unix/linux的根基之一。 几乎所有C程序都要调用glibc的库函数，所以glibc是Linux平台C程序运行的基础。 glibc除了封装linux操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现。 系统调用（system call）是指操作系统提供给程序调用的接口。 glibc中的open,read,write,close,stat,mkdir等函数其实都是是系统调用，准确的讲是系统调用的封装函数。 sync系统调用接下来，我们需要从glibc的sync函数，分析到sync的系统调用。内核的unistd.h头文件在/usr/include/linux/unistd.h，属于kernel-headers这个rpm包。接着又指向/usr/include/asm/unistd.h，根据体系结构，指向unistd_64.h。unistd_64.h 里面看到有__NR_sync的宏定义，162这个数字就是这个sync系统调用的编号。在/usr/include/asm-generic/unistd.h里，指出了源文件和函数名sys_sync。123/* fs/sync.c */#define __NR_sync 81__SYSCALL(__NR_sync, sys_sync) 这里需要注意，在不同的体系结构里，系统调用号是不同的。asm-generic/unistd.h里的sync系统调用编号是81，因为asm-generic这是一个通用的系统调用编号文件，在我们x86_64系统里不适用。我们需要参考asm/unistd_64.h里的编号，也就是162。可以使用gcc编译器命令来查看预定义的宏的调用，也指向asm/unistd_64.h。123456789101112131415161718[root@MiWiFi-R1CM-srv linux]# echo -n &quot;#include &lt;sys/syscall.h&gt;&quot; | gcc -E -# 1 &quot;&lt;stdin&gt;&quot;# 1 &quot;&lt;built-in&gt;&quot;# 1 &quot;&lt;命令行&gt;&quot;# 1 &quot;/usr/include/stdc-predef.h&quot; 1 3 4# 1 &quot;&lt;命令行&gt;&quot; 2# 1 &quot;&lt;stdin&gt;&quot;# 1 &quot;/usr/include/sys/syscall.h&quot; 1 3 4# 24 &quot;/usr/include/sys/syscall.h&quot; 3 4# 1 &quot;/usr/include/asm/unistd.h&quot; 1 3 4# 12 &quot;/usr/include/asm/unistd.h&quot; 3 4# 1 &quot;/usr/include/asm/unistd_64.h&quot; 1 3 4# 13 &quot;/usr/include/asm/unistd.h&quot; 2 3 4# 25 &quot;/usr/include/sys/syscall.h&quot; 2 3 4...# 1 &quot;/usr/include/bits/syscall.h&quot; 1 3 4# 32 &quot;/usr/include/sys/syscall.h&quot; 2 3 4# 1 &quot;&lt;stdin&gt;&quot; 2 由此，可以知道fs/sync.c就是我们要找的源文件。linux-3.10.0-957.5.1.el7.x86_64/fs/sync.c fs/sync.c这个文件包含sync相关的函数定义：High-level sync()-related operations需要注意，这里无法直接找到sync函数定义，需要用宏定义展开SYSCALL_DEFINE0(sync)才能得到sys_sync函数。123456789101112131415161718192021222324/* * Sync everything. We start by waking flusher threads so that most of * writeback runs on all devices in parallel. Then we sync all inodes reliably * which effectively also waits for all flusher threads to finish doing * writeback. At this point all data is on disk so metadata should be stable * and we tell filesystems to sync their metadata via -&gt;sync_fs() calls. * Finally, we writeout all block devices because some filesystems (e.g. ext2) * just write metadata (such as inodes or bitmaps) to block device page cache * and do not sync it on their own in -&gt;sync_fs(). */SYSCALL_DEFINE0(sync)&#123; int nowait = 0, wait = 1; wakeup_flusher_threads(0, WB_REASON_SYNC); iterate_supers(sync_inodes_one_sb, NULL); iterate_supers(sync_fs_one_sb, &amp;nowait); iterate_supers(sync_fs_one_sb, &amp;wait); iterate_bdevs(fdatawrite_one_bdev, NULL); iterate_bdevs(fdatawait_one_bdev, NULL); if (unlikely(laptop_mode)) laptop_sync_completion(); return 0;&#125; SYSCALL_DEFINE0这个宏在linux/syscalls.h里定义：123#define SYSCALL_DEFINE0(sname) \ SYSCALL_METADATA(_##sname, 0); \ asmlinkage long sys_##sname(void) 所以SYSCALL_DEFINE0(sync)展开得到：12SYSCALL_METADATA(_sync, 0); \asmlinkage long sys_sync(void) 至此，我们就得到了sys_sync这个系统调用函数。 sys_sync以及相关实验对于sys_sync这个系统调用函数，非常底层的代码我们不做分析了，内核水太深，我们这里用两个工具来测试。 ftrace跟踪调用过程我们可以用ftrace跟踪sync完整的调用过程。1234567891011121314151617181920212223242526272829[root@MiWiFi-R1CM-srv ~]# cat function.sh #!/bin/bashdebugfs=/sys/kernel/debugecho nop &gt; $debugfs/tracing/current_tracerecho 0 &gt; $debugfs/tracing/tracing_onecho $$ &gt; $debugfs/tracing/set_ftrace_pidecho function_graph &gt; $debugfs/tracing/current_tracer#replace test_proc_show by your function nameecho sys_sync &gt; $debugfs/tracing/set_graph_functionecho 1 &gt; $debugfs/tracing/tracing_onexec &quot;$@&quot;[root@MiWiFi-R1CM-srv ~]# sh function.sh sync[root@MiWiFi-R1CM-srv ~]# cat /sys/kernel/debug/tracing/trace &gt; 1[root@MiWiFi-R1CM-srv ~]# head 1# tracer: function_graph## CPU DURATION FUNCTION CALLS# | | | | | | | 5) | sys_sync() &#123; 5) | wakeup_flusher_threads() &#123; 5) | get_nr_dirty_pages() &#123; 5) | get_nr_dirty_inodes() &#123; 5) 0.163 us | get_nr_inodes(); 5) 0.608 us | &#125; [root@MiWiFi-R1CM-srv ~]# echo 0 &gt; /sys/kernel/debug/tracing/tracing_on 可以参考，还有vim配置用于展开ftrace文件：宋宝华：关于Ftrace的一个完整案例 systemtap验证同步调用我们用systemtap来延长硬件刷盘底层函数时间，来验证上层的sync是一个同步阻塞调用。从代码来看，sync_fs_one_sb, &amp;wait的确是一个同步调用。但是网上搜到的很多资料说sync是一个异步调用，不能保证数据落盘，还要多敲几次，多等待，这点非常存疑（搞笑，那sync命令有什么用？）。使用systemtap来做实验，是比研读内核代码以外更快的验证方法。根据上一篇文章，我们知道，当有刷盘的数据落盘时，一定会执行ata_scsi_flush_xlat这个函数，我们尝试把这个函数延长1秒：123456[root@MiWiFi-R1CM-srv ~]# stap -g -v -e &apos;probe module(&quot;libata&quot;).function(&quot;ata_scsi_flush_xlat&quot;).return &#123;mdelay(1000)&#125;&apos;Pass 1: parsed user script and 470 library scripts using 244796virt/42192res/3488shr/38848data kb, in 210usr/20sys/227real ms.Pass 2: analyzed script: 1 probe, 1 function, 1 embed, 0 globals using 246768virt/45252res/4428shr/40820data kb, in 30usr/50sys/76real ms.Pass 3: using cached /root/.systemtap/cache/0f/stap_0f1684821eb395fa3d8126b925059598_1315.cPass 4: using cached /root/.systemtap/cache/0f/stap_0f1684821eb395fa3d8126b925059598_1315.koPass 5: starting run. 新开一个终端：可以看到，sync的时间明显变长，而且一直卡住直到结束。可以说明sync这是一个同步调用，会保证数据落盘再返回。12345678910111213[root@MiWiFi-R1CM-srv ~]# touch 2[root@MiWiFi-R1CM-srv ~]# time syncreal 0m2.007suser 0m0.334ssys 0m0.668s[root@MiWiFi-R1CM-srv ~]# touch 3[root@MiWiFi-R1CM-srv ~]# time syncreal 0m1.961suser 0m0.000ssys 0m0.001s 参考不详述所有参考，贴一些重要的：Anatomy of a system call, part 1Anatomy of a system call, part 1]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>刷盘</tag>
        <tag>SCSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全链路分析数据落盘机制-硬件及驱动层]]></title>
    <url>%2F2019%2F03%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6-%E7%A1%AC%E4%BB%B6%E5%8F%8A%E9%A9%B1%E5%8A%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[前言数据落盘，顾名思义，就是数据写入最终的非易失（Non-volatile）的存储介质，例如HDD（磁性介质）、SSD（半导体介质）等，当服务器故障或异常掉电时，数据做到不丢失。由于硬件故障是经常发生的，对数据安全性要求高的场景，例如金融类的数据库、日志、消息等，数据落盘非常重要，有时甚至是一个企业的底线。本文尝试从底层硬件开始，向上逐层讲到应用，来说明数据落盘的路径，以及如何保证数据落盘，并且重点放在实验验证。 重点问题及知识点 当应用发起写入数据的请求返回OK时，数据是否真的到达了磁盘，有哪些因素在起作用？ 应用程序的写入参数、文件系统参数、硬件参数是如何保证数据落盘的？ 今天的x86硬件体系结构，服务器硬件层面，有哪些硬件write cache，断电是否数据丢失？ 数据落盘，很重要的“刷盘”命令，硬件层面到底是什么？ 掉电保护和“刷盘”的关系是什么，是否就不用“刷盘”了？ SCSI和ATA到底是什么关系，为什么我用的SATA盘识别成SCSI设备？ 环境还是我的这台机器，sdb是SATA SSD，sdc是SATA HDD。它们连接在PCH（南桥），走AHCI控制器。1234567891011121314Summary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GBDisk: sda (scsi0): 240GB (7%) JBOD == 1 x 240GB Gen3 signaling speed (6.0Gb/s) LITEON-EGT-240N9SDisk: sdb: 100GB JBOD == 1 x 100GB SATA 300MB/s INTEL-SSDSA2BZ100G3Disk: sdc (scsi2): 1.0TB JBOD == 1 x 1.0TB Gen3 signaling speed (6.0Gb/s) WDC-WD10JPLX-00MBPT1Disk-Control: ahci0: Intel 200 Series PCH SATA controller [AHCI mode]Network: 00:1f.6 (e1000e0): Intel Ethernet Connection (2) I219-VNetwork: 02:00.0 (igb0): Intel I211 GigabitNetwork: 03:00.0 (iwlwifi0): Intel Dual Band Wireless-AC 3168NGW [Stone Peak]OS: CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.5.1.el7.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R1CM-srv 硬件层硬件存储体系简述在x86服务器上，本地存储介质的连接方式主要有以下几种， 表示互相连接。 内存 CPU Raid/HBA卡 SATA/SAS HDD/SSD 内存 CPU PCH SATA HDD/SSD 内存 CPU PCIe/NVMe SSD CPU包含内存控制器，直连内存。内存一般存放应用自身维护的cache和系统的page cache，内存当然是掉电数据丢失的。为了提升性能，Raid卡、HDD、SSD都有自身的write cache，这些write cache是影响落盘的硬件层面因素。 HDD/SSD write cache这里简单测试一下就好。我们可以用hdparm来查看、关闭、打开write cache。这里少于ms级的数据写入时间，明显是HDD的write cache的返回。12345678[root@MiWiFi-R1CM-srv ata]# hdparm -W /dev/sdc/dev/sdc: write-caching = 1 (on)[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct记录了1+0 的读入记录了1+0 的写出4096字节(4.1 kB)已复制，0.000929063 秒，4.4 MB/秒 可以看到，关闭HDD cache对写入的延迟影响是巨大的。123456789[root@MiWiFi-R1CM-srv ata]# hdparm -W 0 /dev/sdc/dev/sdc: setting drive write-caching to 0 (off) write-caching = 0 (off)[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct记录了1+0 的读入记录了1+0 的写出4096字节(4.1 kB)已复制，0.042402 秒，96.6 kB/秒 刷盘指令由于write cache enable后，掉电数据丢失，为了保证数据落盘，也就引出了刷盘命令。简单的说，刷盘是把HDD/SSD write cache里的数据写入存储介质（碟片/Nand），数据写入完毕后，再返回OK。 可以参考wikipedia关于刷盘的介绍。 https://en.wikipedia.org/wiki/Disk_bufferCache flushingData that was accepted in write cache of a disk device will be eventually written to disk platters, provided that no starvation condition occurs as a result of firmware flaw, and that disk power supply is not interrupted before cached writes are forced to disk platters. In order to control write cache, ATA specification included FLUSH CACHE (E7h) and FLUSH CACHE EXT (EAh) commands. These commands cause the disk to complete writing data from its cache, and disk will return good status after data in the write cache is written to disk media. In addition, flushing the cache can be initiated at least to some disks by issuing Soft reset or Standby (Immediate) command.[4] 在ATA Command Set里，定义了FLUSH CACHE (E7h) 和 FLUSH CACHE EXT (EAh) 这两个指令用于刷盘。这里FLUSH_CACHE是用于支持28bit LBA长度的命令的存储设备的，最大137GB硬盘，目前已经淘汰。今天的刷盘命令，都是指FLUSH_CACHE_EXT，即48bit LBA长度的命令。我们可以看看行业规范如何定义这个命令： The FLUSH CACHE EXT command requests the device to flush the volatile write cache. If there is data in the volatile write cache, that data shall be written to the non-volatile media. This command shall not indicate completion until the data is flushed to the non-volatile media or an error occurs. If the volatile write cache is disabled or no volatile write cache is present, the device shall indicate command completion without error. 链接：ATAATAPI_Command_Set 掉电保护刷盘这个指令当时是为了解决HDD掉电write cache数据一定丢失的问题，在Nand介质出现以后，引入了掉电数据保护功能。掉电数据保护 power loss protection (PLP)，指的是服务器异常断电时，存储设备能把write cache里的数据写回介质。以下总结适用于普通的x86服务器，以下都是Write cache enable场景。 企业级SSD、包含SATA/SAS/PCIe/NVMe SSD等，通过超级电容保证断电时把write cache中的数据写回Nand。 消费级SSD由于面向的客户群体及成本考虑，不带掉电数据保护，掉电时cache数据存在丢失几率。 HDD，无论企业级还是消费级，都不带掉电保护功能。因为驱动12V和5V的马达保证转速并写入数据对功率要求较大。 Raid卡一般配置电池或超级电容，断电后把write cache的数据临时写入Raid卡的板载Nand颗粒上。当服务器上电后，Raid卡重新把Nand的数据写回HDD。当使用Raid卡时，Raid卡默认关闭HDD的write cache，避免Raid卡不丢数据，但是HDD丢数据。 什么时候不用刷盘由上文可知，支持掉电保护的硬件，是不需要刷盘的。例如： 数据到达带电池/超级电容的Raid卡write cache，即向上层返回写入OK，可以认为数据落盘（默认关闭HDD write cache）。 没有raid卡，数据到达企业级SSD的write cache，即向上层返回写入OK，可以认为数据落盘。 你的设备是否支持掉电保护，请以你实际的硬件设备为准，在引入生产之前，查看供应商的测试报告和自己进行测试。 什么时候需要刷盘如果不支持掉电保护同时write cache enable，就需要刷盘，也就是下发FLUSH_CACHE_EXT，并等待这条指令返回OK，才可以认为数据落盘。 驱动层在硬件（包含硬件firmware）之上，就是驱动层了，由于我用的是SATA HDD/SSD，ATA驱动是SCSI子系统的一部分，所以这里重点看SCSI子系统如何下发FLUSH_CACHE_EXT命令。如果你使用的是PCIe/NVMe SSD，则不经过SCSI子系统，NVMe驱动直接到块设备层。 关于SCSI子系统、NVMe的IO路径，可以参考这幅著名的Linux IO stack图。连接：Linux Storage Stack Diagram SCSI和ATA的转换这里有一个非常关键的知识点：在Linux内核里，除了NVMe以外，存储设备都是在SCSI体系内管理的。应用层的读写操作，会以bio的形式提交给block层，然后，block会把bio转换成request，并把该request加入到专为某个SCSI device服务的request queue中，接下来会有内核线程适时地从该queue中摘取request，并转换成SCSI cmd，再转换成ATA cmd，最终交由AHCI Controller（对于AHCI，实际上会把ATA cmd转换成FIS结构）发向硬盘执行。参考：request到ATA cmd的转换过程 我们接下来看看下发的SCSI的具体指令，打开scsi的日志信息，注意这里是-1。参考：Linux 开启 SCSI 日志调试功能12345scsi_logging_level 值可以在 boot 命令行设置也可以开启设备后在 /proc 文件系统中设置：-1 - Enable scsi events to syslog. // 开启所有scsi log0 - Disable scsi events to syslog. // 关闭所有scsi log命令: echo 0/-1 &gt; /proc/sys/dev/scsi/logging_level 我们知道sync命令就有刷盘的功能，执行一次再看看dmesg日志。这里下发了CDB 35H12345678[47505.162954] sd 0:0:0:0: [sda] tag#5 Send: scmd 0xffff97b61d238fc0[47505.162965] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00[47505.163957] sd 0:0:0:0: [sda] tag#5 Done: SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK[47505.163974] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00[47505.163985] sd 0:0:0:0: [sda] tag#5 scsi host busy 1 failed 0[47505.164003] sd 0:0:0:0: Notifying upper driver of completion (result 0)[47505.164013] sd 0:0:0:0: [sda] tag#5 sd_done: completed 0 of 0 bytes[47505.164023] sd 0:0:0:0: [sda] tag#5 0 sectors total, 0 bytes done. 在SCSI命令集里，35h指令对应的是SYNCHRONIZE CACHE，也就是刷盘。The SYNCHRONIZE CACHE (10) command (see table 199) requests that the device server ensure that the specified logical blocks have their most recent data values recorded in non-volatile cache and/or on the medium.参考：SCSI Commands Reference Manual 刷盘命令的转换SCSI的SYNCHRONIZE CACHE，ATA的FLUSH CACHE EXT，这是两条刷盘命令。我用的是SATA HDD/SSD，是在SCSI体系里使用ATA设备，刷盘命令也需要转换。通过搜索官方文档，可以看到libata-scsi.c里的ata_scsi_flush_xlat函数，就是做这个事。12345ata_scsi_flush_xlatTranslate SCSI SYNCHRONIZE CACHE commandDescriptionSets up an ATA taskfile to issue FLUSH CACHE or FLUSH CACHE EXT. 参考：The Linux driver implementer’s API guide » libATA Developer’s Guide 跟踪一下sync的在libata内核模块的执行路径，这里用到systemtap。在ata_scsi_queuecmd里，可以看到 SCSI cmd -&gt; ATA cmd -&gt; FIS 这个过程。1234567891011121314151617181920212223242526272829[root@MiWiFi-R1CM-srv ~]# cat libata.stp #!/usr/bin/stap -vprobe module(&quot;libata&quot;).function(&quot;*&quot;).call &#123; printf (&quot;Call : %s -&gt; %s\n&quot;, thread_indent(2) ,ppfunc())&#125;probe module(&quot;libata&quot;).function(&quot;*&quot;).return &#123; printf (&quot;Return: %s &lt;- %s\n&quot;, thread_indent(-2) ,ppfunc())&#125;[root@MiWiFi-R1CM-srv ~]# stap libata.stp Call : 0 sync(9551): -&gt; ata_scsi_queuecmdCall : 2 sync(9551): -&gt; ata_scsi_find_devCall : 3 sync(9551): -&gt; __ata_scsi_find_devCall : 4 sync(9551): -&gt; ata_find_devReturn: 5 sync(9551): &lt;- ata_find_devReturn: 6 sync(9551): &lt;- __ata_scsi_find_devReturn: 7 sync(9551): &lt;- ata_scsi_find_devCall : 8 sync(9551): -&gt; ata_qc_new_initReturn: 8 sync(9551): &lt;- ata_qc_new_initCall : 10 sync(9551): -&gt; ata_scsi_flush_xlatReturn: 11 sync(9551): &lt;- ata_scsi_flush_xlatCall : 12 sync(9551): -&gt; ata_std_qc_deferReturn: 13 sync(9551): &lt;- ata_std_qc_deferCall : 13 sync(9551): -&gt; ata_qc_issueCall : 14 sync(9551): -&gt; ata_tf_to_fisReturn: 15 sync(9551): &lt;- ata_tf_to_fisReturn: 16 sync(9551): &lt;- ata_qc_issueReturn: 17 sync(9551): &lt;- ata_scsi_queuecmd 查看ata_tf_to_fis函数的结构体tf-&gt;command，可以看到sync转换之后，发出的ATA CMD是EAh，也就是上一章里的FLUSH CACHE EXT (EAh) commands。12345678[root@MiWiFi-R1CM-srv ~]# cat ata_tf_to_fis.stp #!/usr/bin/stap -vprobe module(&quot;libata&quot;).function(&quot;ata_tf_to_fis&quot;).call &#123; printf (&quot;Call : %s -&gt; %s -&gt; %4x\n&quot;, thread_indent(0) ,ppfunc(), $tf-&gt;command)&#125;Call : 0 sync(10614): -&gt; ata_tf_to_fis -&gt; ea 至此，通过驱动层，我们知道，在SCSI子系统里，刷盘是SYNCHRONIZE CACHE这条SCSI命令，经过转换为ATA命令，发到磁盘上是FLUSH CACHE EXT。 总结 带掉电保护的设备，不需要刷盘。 write cache enable时，不带掉电保护的设备，需要刷盘。 ATA标准是T13，刷盘命令是Flush cache ext，代码EAh。 SCSI标准是T10，刷盘命令是Synchronize Cache，代码35h。 bio转换成request，request转换成SCSI命令，SCSI命令转换为ATA命令，AHCI把ATA命令转换为FIS结构发向硬盘。 libata-scsi.c里的ata_scsi_flush_xlat函数进行刷盘命令从SCSI到ATA的转换。 参考本文引用了很多文章，这里附上额外的一些参考，一并致谢。 In what sense does SATA “talk” SCSI? How much is shared between SCSI and ATA?]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>刷盘</tag>
        <tag>SCSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用wireguard打通内网机器和外网云服务器]]></title>
    <url>%2F2019%2F03%2F%E4%BD%BF%E7%94%A8wireguard%E6%89%93%E9%80%9A%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8%E5%92%8C%E5%A4%96%E7%BD%91%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[场景这是我个人的需求，但是也有借鉴意义。需要在外部连接家里的机器做测试，家里路由器拨号之后没有公网IP，所以使用一台具有公网IP的阿里云ECS服务器作为中转，打通内网的机器和阿里云服务器。在以往，我会使用strongswan来搭建IKEv2的VPN来实现这个需求，但是现在有更简单好用的wireguard了。 wireguard介绍毕竟是VPN软件，所以需要翻墙访问。wireguard官网wireguard官网的视频介绍 环境两台CentOS 7.6，都可以访问公网。A机器仅有内网IP，B机器有公网IP和内网IP。 配置方式1234567891011121314151617181920212223242526272829303132333435A机器(家里)内网(192.168.31.0/24)B机器(ECS)内网(172.16.100.0/24)分别在每个机器执行:yum install -y epel-releasecurl -Lo /etc/yum.repos.d/wireguard.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repoyum install wireguard-dkms wireguard-tools -ymkdir -p /etc/wireguardumask 077cd /etc/wireguardwg genkey | tee privatekey | wg pubkey &gt; publickeyvim wg0.conf 内容如下:[Interface]PrivateKey = 本机的privatekeyListenPort = 2503PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEPostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADEMTU = 1500[Peer]PublicKey = 远端的publickeyEndpoint = 远端的ip:2503（公网ip，至少需要一端有，没有就不写）AllowedIPs = 远端的网段启动systemctl start wg-quick@wg0.service echo &apos;net.ipv4.ip_forward = 1&apos; &gt;&gt; /etc/sysctl.conf 启用转发sysctl -p 分别A,B机器启动, 然后ping对方, 谁先ping, 谁就发起连接。由于我的环境里，只有阿里云ECS才有公网IP，所以我只能由家里机器发起ping。配置上开机启动服务。systemctl enable wg-quick@wg0.service 要开机自动连接到阿里云，就写个crontab的ping，每分钟ping一次好了。这里我使用家里的机器，ping阿里云服务器的内网IP，即可自动建立连接。123456789101112131415161718[root@MiWiFi-R1CM-srv ~]# cat /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed* * * * * root ping -c1 172.16.100.38 &amp;&gt; /dev/nullwg show 查看状态 由于wireguard是内核模块，需要注意内核各个rpm包小版本一致。例如我这里，都是3.10.0-957.5.1.el7.x86_64这个小版本。12345678[root@MiWiFi-R1CM-srv ~]# rpm -qa | grep kernelkernel-3.10.0-957.5.1.el7.x86_64kernel-headers-3.10.0-957.5.1.el7.x86_64kernel-tools-libs-3.10.0-957.5.1.el7.x86_64kernel-devel-3.10.0-957.5.1.el7.x86_64kernel-debuginfo-3.10.0-957.5.1.el7.x86_64kernel-tools-3.10.0-957.5.1.el7.x86_64kernel-debuginfo-common-x86_64-3.10.0-957.5.1.el7.x86_64 解决ssh长输出变卡从远程通过wireguard vpn连接到本地机器时，ssh之后敲命令正常，但是长输出命令就会卡住，例如dmesg。这种问题是由于MTU造成的丢包重传延迟。把cat /etc/wireguard/wg0.conf配置文件里的MTU =1500设置小一点，例如1400，我这边问题解决，dmesg命令秒开。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VPN</tag>
        <tag>wireguard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[纠正几个Linux的IO监控指标的误区]]></title>
    <url>%2F2019%2F03%2F%E7%BA%A0%E6%AD%A3%E5%87%A0%E4%B8%AALinux%E7%9A%84IO%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87%E7%9A%84%E8%AF%AF%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[前言本文主要面向初级工程师，假设你已经对的Linux性能监控工具有所了解，例如top、vmstat、mpstat、iostat等。 日常工作中，碰到IO性能问题是常有的事，本文主要探讨Linux下的IO监控里容易产生误区的点。 这些误区，一方面是因为工程师想当然，不仔细看文档，不理解底层细节。另一方面是因为Linux内核和监控工具的发展，落后于存储设备硬件的发展，软硬件发展存在脱节，因此监控工具不能反映硬件的真实情况。 纠正这些误区，对这些监控和背后原理理解越深刻，越能评估一个系统性能的真实情况，定位和解决问题也更容易。 环境12345678910Summary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GBDisk: sda (scsi0): 240GB (0%) JBOD == 1 x LITEON-EGT-240N9SDisk: sdb: 100GB JBOD == 1 x INTEL-SSDSA2BZ100G3Disk: sdc (scsi2): 1.0TB JBOD == 1 x WDC-WD10JPLX-00MBPT1OS: CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.10.1.el7.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R1CM-srv 这是一台普通的x86台式机，sdb是Intel SSD 710 Series，sdc是西数的7200转黑盘。使用这两块盘来做后面的实验。 正文下面介绍四个容易产生误区的指标，分别是%iowait、await、svctm、%util。顺序上会把%util放在svctm之前介绍。 %iowait 正确：%iowait（wa）是CPU的一种IDLE，%iowait大小不能用来反映IO瓶颈。 误区：（1）%iowait高，CPU很忙。（2）%iowait高，磁盘IO瓶颈。 解释%iowait（来自mpstat）和wa（来自top、vmstat）是同一个指标，表示在一个采样周期内，CPU空闲在等待未完成的IO请求所占的白分比。iowait的产生要满足两个条件，一是进程在等io，二是等io时没有进程可运行。 误区（1）%iowait高，CPU很忙。先看官方文档说明：123456man vmstatwa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.man mpstat%iowaitShow the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. 文档已经明确显示，%iowait是一种IDLE，尤其在2.5.41以前的旧内核里，%iowait是直接统计在idle里的。既然%iowait的显示的百分比是一种IDLE，它是可以被其它进程使用的。%iowait高，CPU其实很闲，因为其它进程都在随眠。 实验验证12345678910111213141516171819202122232425262728293031323334353637383940414243在这台完全空闲的机器上，对sdc进行随机读，可以看到IOPS大约是60多，这与7200rpm的机械硬盘性能是相符的。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1fio-3.1Starting 1 threadJobs: 1 (f=1): [r(1)][6.7%][r=252KiB/s,w=0KiB/s][r=63,w=0 IOPS][eta 02m:48s]此时，我们看%iowait，可以看到在核心6上，100%的iowait。top - 22:27:51 up 3:08, 3 users, load average: 2.37, 2.40, 1.31Tasks: 157 total, 1 running, 156 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.0 us, 0.3 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 0.0 us, 0.3 sy, 0.0 ni, 0.0 id, 99.7 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11211948 free, 290604 used, 4431532 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14941848 avail Mem 这时，我们起一个stress打满CPU看看。[root@MiWiFi-R1CM-srv ~]# stress -c 6stress: info: [9856] dispatching hogs: 6 cpu, 0 io, 0 vm, 0 hdd可以看到，起了6个stress打满了6个核心，fio进程还在运行，但是%iowait已经被“吃掉”了，说明这部分IDLE的CPU时间片已经被stress征用了。top - 22:28:36 up 3:09, 3 users, load average: 3.63, 2.67, 1.45Tasks: 162 total, 7 running, 155 sleeping, 0 stopped, 0 zombie%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 99.7 us, 0.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 99.7 us, 0.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11208508 free, 293992 used, 4431584 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14938420 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 9857 root 20 0 7308 96 0 R 100.0 0.0 0:22.69 stress 9861 root 20 0 7308 96 0 R 100.0 0.0 0:22.71 stress 9862 root 20 0 7308 96 0 R 100.0 0.0 0:22.71 stress 9858 root 20 0 7308 96 0 R 99.7 0.0 0:22.67 stress 9859 root 20 0 7308 96 0 R 99.7 0.0 0:22.68 stress 9860 root 20 0 7308 96 0 R 99.7 0.0 0:22.70 stress 9834 root 20 0 1091604 293556 261636 S 0.3 1.8 0:01.06 fio 误区（2）%iowait高，磁盘IO瓶颈。由之前的解释可以看到，这个指标是描述CPU的IDLE的，它与磁盘IO是否到达瓶颈一点关系都没有，它都不是一个用来描述磁盘IO性能的指标。 实验验证1234567891011121314151617181920212223242526272829303132333435363738394041这个实验使用ssd，如下fio命令，在6个进程下，ssd的随机读性能是25k iops，%iowait超过80%。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 6 threadsJobs: 6 (f=6): [r(6)][20.0%][r=97.0MiB/s,w=0KiB/s][r=25.1k,w=0 IOPS][eta 02m:24s] top - 22:45:45 up 3:26, 3 users, load average: 4.68, 2.59, 1.81Tasks: 158 total, 1 running, 157 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.7 us, 6.7 sy, 0.0 ni, 3.4 id, 89.2 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 1.3 us, 6.4 sy, 0.0 ni, 1.3 id, 91.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 1.3 us, 7.0 sy, 0.0 ni, 3.7 id, 88.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.7 us, 7.0 sy, 0.0 ni, 2.0 id, 90.3 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 1.3 us, 6.7 sy, 0.0 ni, 1.3 id, 90.6 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 1.7 us, 7.3 sy, 0.0 ni, 5.2 id, 83.3 wa, 0.0 hi, 2.6 si, 0.0 stKiB Mem : 15934084 total, 11223276 free, 278992 used, 4431816 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14953420 avail Mem 还是这块盘，ioengine我们从psync改成aio，同时把iodepth从1改成了8，可以看到44k的IOPS，但是%iowait却是0。这里说明，%iowait大小与磁盘瓶颈毫无关系，由于aio是异步的，CPU不需要IDLE等待IO，也就不会产生%iowait。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8...fio-3.1Starting 6 threadsJobs: 6 (f=6): [r(6)][5.6%][r=173MiB/s,w=0KiB/s][r=44.2k,w=0 IOPS][eta 02m:50s]top - 22:49:31 up 3:30, 3 users, load average: 1.14, 2.61, 2.06Tasks: 156 total, 1 running, 155 sleeping, 0 stopped, 0 zombie%Cpu0 : 3.0 us, 4.0 sy, 0.0 ni, 93.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 2.0 us, 3.0 sy, 0.0 ni, 95.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.3 us, 0.7 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 5.8 us, 6.9 sy, 0.0 ni, 87.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11219948 free, 282280 used, 4431856 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14950088 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 10091 root 20 0 1431564 281112 261664 S 33.6 1.8 0:26.54 fio await 正确：表示IO从创建到完成的平均时间，包含IO排队时间+存储设备处理时间。 误区：（1）混淆%iowait和await。（2）认为await高等于磁盘慢。 解释await是iostat里的指标，iostat属于sysstat这个rpm包。await表示平均每个IO所需要的时间，包括在队列等待的时间，也包括磁盘控制器处理本次请求的有效时间。123456789man iostatawaitThe average time (in milliseconds) for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.这里借用blktrace的blkparse显示的各指标点，await是从IO到达block层开始算起，包含排队时间，到最后IO完毕。Q-------&gt;G------------&gt;I---------&gt;M-------------------&gt;D-----------------------------&gt;C|-Q time-|-Insert time-||--------- merge time ------------|-merge with other IO||----------------scheduler time time-------------------|---driver,adapter,storagetime--| 误区（1）混淆%iowait和await。在工作中，我遇到过几次运维和研发人员混淆这两个概念的，弄清楚并在表述的时候注意即可。 误区（2）认为await高等于磁盘慢。await包含了队列时间，我们只需要保持磁盘压力不变的情况下，增加队列深度即可验证这个问题。 实验验证1234567891011121314151617181920212223这里，我们限制IOPS为100，先用队列深度8，可以看到await 80。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8fio-3.1Starting 1 threadJobs: 1 (f=1), 0-100 IOPS: [r(1)][5.6%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:50s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 97.00 0.00 0.38 0.00 8.00 8.00 84.79 84.79 0.00 10.31 100.00sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00还是限制IOPS为100，队列深度调高到16，可以看到，IOPS不变的情况下，await增加到110左右。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 16 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16fio-3.1Starting 1 threadJobs: 1 (f=1), 0-100 IOPS: [r(1)][8.3%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:45s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 101.00 0.00 0.39 0.00 8.00 11.93 109.34 109.34 0.00 9.86 99.60sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 %util 正确：iostat里的%util并不能准确反映存储设备使用率（或者称为饱和率）。 误区：%util就是存储设备硬件的使用率，达到100%时就到磁盘瓶颈了。 解释%util估算了一个使用率，但是存储设备的使用率以及是否饱和，是没有接口告诉Linux系统的。%util通过/proc/diskstats计算得到，不关心等待在队里里面IO的个数，它只关心队列中有没有IO。。整个计算方式把存储设备当做只能串行处理IO的磁盘，当使用支持并发处理IO的存储设备时，此项就不准确了。当%util是100%时，代表Linux队列里一直有IO，但不能代表硬件存储设备已经饱和。123456在sysstat网站的最新文档中也已经注明： But for devices serving requests in parallel, such as RAID arrays and modern SSDs, this number does not reflect their performance limits.文档地址：http://sebastien.godard.pagesperso-orange.fr/man_iostat.html%utilPercentage of elapsed time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100%. 实验验证由于%util是以单并发的存储设备设计的，只要是支持多并发的存储设备，%util就不准确了。提升并发数，即可验证这个问题。12345678910111213141516171819202122232425同样的测试用例，我们num-jobs从4改到8，可以看到，使用率都是100%，但是IOPS有巨大的不同。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 4 threadsJobs: 4 (f=4): [r(4)][3.3%][r=74.7MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:54s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 18078.00 0.00 70.62 0.00 8.00 3.57 0.20 0.20 0.00 0.06 100.00[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=8 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 8 threadsJobs: 8 (f=8): [r(8)][7.8%][r=110MiB/s,w=0KiB/s][r=28.2k,w=0 IOPS][eta 02m:46s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 28233.00 0.00 110.29 0.00 8.00 7.31 0.26 0.26 0.00 0.04 100.00 svctm 正确：iostat里的svctm并不能准确反映存储设备的处理时间。 误区：svctm就是存储设备硬件处理IO的时间。 解释从官方文档可以看到，Do not trust this field any more.实际上，iostat获取这个svctm仅是通过一个简单计算。iostat计算svctm需要使用%util，但%util在多并发IO里，本身就是不准确的，所以间接造成svctm也不准确。12svctmThe average service time (in milliseconds) for I/O requests that were issued to the device. Warning! Do not trust this field any more. This field will be removed in a future sysstat version. 实验验证对于相同的IO模型，存储设备的处理时间都应该是一样的。如果压力越大，存储设备处理时间应该越长才对。我们验证svctm是否和真实情况一样。123456789101112131415161718192021222324我们使用SSD做实验，可以看到，当从4个并发提升到32个并发时，IOPS从19k提升到44k，但是svctm却从0.05ms下降到0.02ms，明显不符合现实。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 4 threadsJobs: 4 (f=4): [r(4)][5.0%][r=74.6MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:51s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 19069.00 0.00 74.49 0.00 8.00 3.90 0.20 0.20 0.00 0.05 100.00[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=32 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 32 threadsJobs: 32 (f=32): [r(32)][31.7%][r=172MiB/s,w=0KiB/s][r=44.1k,w=0 IOPS][eta 02m:03s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 44080.00 0.00 172.19 0.00 8.00 31.37 0.71 0.71 0.00 0.02 100.00 总结 %iowait并没有提供什么有效信息，因为它是描述IDLE的。 %iowait大小受CPU的负载变化而变化，这个指标如果很大，除了能说明CPU很闲在等待IO以外，并不能反映IO压力或者瓶颈。另外，aio不会使CPU产生%iowait。 iostat提供了基本的监控数据，但是分析IO瓶颈，关键是去看Linux的IO的监控指标是否打满了存储设备的真实性能，因此必须对存储设备在当前IO模型下具备的真实性能有所了解。 这些值虽然不够准确，但是在生产环境中，仍然具备参考意义：当你的业务类型和压力没有任何变化时，如果这些值偏离了基线（baseline）或者历史平均值，则你需要去排查是否哪里出了问题。 参考资料本文讲解并不深入，更多的是实验思路。建议阅读下列文章，包含原理性的解释，一并致谢：朱辉(茶水)： Linux Kernel iowait 时间的代码原理 深入理解iostat 辩证看待 iostat 深入理解磁盘IO利用率及饱和度]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>性能监控</tag>
      </tags>
  </entry>
</search>
