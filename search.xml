<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[全链路分析数据落盘机制]]></title>
    <url>%2F2019%2F03%2F%E5%85%A8%E9%93%BE%E8%B7%AF%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E8%90%BD%E7%9B%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言数据落盘，顾名思义，就是数据写入最终的非易失（Non-volatile）的存储介质，例如HDD（磁性介质）、SSD（半导体介质）等，当服务器故障或异常掉电时，数据做到不丢失。由于硬件故障是经常发生的，对数据安全性要求高的场景，例如金融类的数据库、日志、消息等，数据落盘非常重要，有时甚至是一个企业的底线。本文尝试从底层硬件开始，向上逐层讲到应用，来说明数据落盘的路径，以及如何保证数据落盘，并且重点放在实验验证。 重点问题及知识点 当应用发起写入数据的请求返回OK时，数据是否真的到达了磁盘，有哪些因素在起作用？ 应用程序的写入参数、文件系统参数、硬件参数是如何保证数据落盘的？ 今天的x86硬件体系结构，服务器硬件层面，有哪些硬件write cache，断电是否数据丢失？ 数据落盘，很重要的“刷盘”命令，硬件层面到底是什么？ 掉电保护和“刷盘”的关系是什么，是否就不用“刷盘”了？ SCSI和ATA到底是什么关系，为什么我用的SATA盘识别成SCSI设备？ 环境还是我的这台机器，sdb是SATA SSD，sdc是SATA HDD。它们连接在PCH（南桥），走AHCI控制器。1234567891011121314Summary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GBDisk: sda (scsi0): 240GB (7%) JBOD == 1 x 240GB Gen3 signaling speed (6.0Gb/s) LITEON-EGT-240N9SDisk: sdb: 100GB JBOD == 1 x 100GB SATA 300MB/s INTEL-SSDSA2BZ100G3Disk: sdc (scsi2): 1.0TB JBOD == 1 x 1.0TB Gen3 signaling speed (6.0Gb/s) WDC-WD10JPLX-00MBPT1Disk-Control: ahci0: Intel 200 Series PCH SATA controller [AHCI mode]Network: 00:1f.6 (e1000e0): Intel Ethernet Connection (2) I219-VNetwork: 02:00.0 (igb0): Intel I211 GigabitNetwork: 03:00.0 (iwlwifi0): Intel Dual Band Wireless-AC 3168NGW [Stone Peak]OS: CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.5.1.el7.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R1CM-srv 硬件层硬件存储体系简述在x86服务器上，本地存储介质的连接方式主要有以下几种， 表示互相连接。 内存 CPU Raid/HBA卡 SATA/SAS HDD/SSD 内存 CPU PCH SATA HDD/SSD 内存 CPU PCIe/NVMe SSD CPU包含内存控制器，直连内存。内存一般存放应用自身维护的cache和系统的page cache，内存当然是掉电数据丢失的。为了提升性能，Raid卡、HDD、SSD都有自身的write cache，这些write cache是影响落盘的硬件层面因素。 HDD/SSD write cache这里简单测试一下就好。我们可以用hdparm来查看、关闭、打开write cache。这里少于ms级的数据写入时间，明显是HDD的write cache的返回。12345678[root@MiWiFi-R1CM-srv ata]# hdparm -W /dev/sdc/dev/sdc: write-caching = 1 (on)[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct记录了1+0 的读入记录了1+0 的写出4096字节(4.1 kB)已复制，0.000929063 秒，4.4 MB/秒 可以看到，关闭HDD cache对写入的延迟影响是巨大的。123456789[root@MiWiFi-R1CM-srv ata]# hdparm -W 0 /dev/sdc/dev/sdc: setting drive write-caching to 0 (off) write-caching = 0 (off)[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct记录了1+0 的读入记录了1+0 的写出4096字节(4.1 kB)已复制，0.042402 秒，96.6 kB/秒 刷盘指令由于write cache enable后，掉电数据丢失，为了保证数据落盘，也就引出了刷盘命令。简单的说，刷盘是把HDD/SSD write cache里的数据写入存储介质（碟片/Nand），数据写入完毕后，再返回OK。 可以参考wikipedia关于刷盘的介绍。 https://en.wikipedia.org/wiki/Disk_bufferCache flushingData that was accepted in write cache of a disk device will be eventually written to disk platters, provided that no starvation condition occurs as a result of firmware flaw, and that disk power supply is not interrupted before cached writes are forced to disk platters. In order to control write cache, ATA specification included FLUSH CACHE (E7h) and FLUSH CACHE EXT (EAh) commands. These commands cause the disk to complete writing data from its cache, and disk will return good status after data in the write cache is written to disk media. In addition, flushing the cache can be initiated at least to some disks by issuing Soft reset or Standby (Immediate) command.[4] 在ATA Command Set里，定义了FLUSH CACHE (E7h) 和 FLUSH CACHE EXT (EAh) 这两个指令用于刷盘。这里FLUSH_CACHE是用于支持28bit LBA长度的命令的存储设备的，最大137GB硬盘，目前已经淘汰。今天的刷盘命令，都是指FLUSH_CACHE_EXT，即48bit LBA长度的命令。我们可以看看行业规范如何定义这个命令： The FLUSH CACHE EXT command requests the device to flush the volatile write cache. If there is data in the volatile write cache, that data shall be written to the non-volatile media. This command shall not indicate completion until the data is flushed to the non-volatile media or an error occurs. If the volatile write cache is disabled or no volatile write cache is present, the device shall indicate command completion without error. 链接：ATAATAPI_Command_Set 掉电保护刷盘这个指令当时是为了解决HDD掉电write cache数据一定丢失的问题，在Nand介质出现以后，引入了掉电数据保护功能。掉电数据保护 power loss protection (PLP)，指的是服务器异常断电时，存储设备能把write cache里的数据写回介质。以下总结适用于普通的x86服务器，以下都是Write cache enable场景。 企业级SSD、包含SATA/SAS/PCIe/NVMe SSD等，通过超级电容保证断电时把write cache中的数据写回Nand。 消费级SSD由于面向的客户群体及成本考虑，不带掉电数据保护，掉电时cache数据存在丢失几率。 HDD，无论企业级还是消费级，都不带掉电保护功能。因为驱动12V和5V的马达保证转速并写入数据对功率要求较大。 Raid卡一般配置电池或超级电容，断电后把write cache的数据临时写入Raid卡的板载Nand颗粒上。当服务器上电后，Raid卡重新把Nand的数据写回HDD。当使用Raid卡时，Raid卡默认关闭HDD的write cache，避免Raid卡不丢数据，但是HDD丢数据。 什么时候不用刷盘由上文可知，支持掉电保护的硬件，是不需要刷盘的。例如： 数据到达带电池/超级电容的Raid卡write cache，即向上层返回写入OK，可以认为数据落盘（默认关闭HDD write cache）。 没有raid卡，数据到达企业级SSD的write cache，即向上层返回写入OK，可以认为数据落盘。 你的设备是否支持掉电保护，请以你实际的硬件设备为准，在引入生产之前，查看供应商的测试报告和自己进行测试。 什么时候需要刷盘如果不支持掉电保护同时write cache enable，就需要刷盘，也就是下发FLUSH_CACHE_EXT，并等待这条指令返回OK，才可以认为数据落盘。 驱动层在硬件（包含硬件firmware）之上，就是驱动层了，由于我用的是SATA HDD/SSD，ATA驱动是SCSI子系统的一部分，所以这里重点看SCSI子系统如何下发FLUSH_CACHE_EXT命令。如果你使用的是PCIe/NVMe SSD，则不经过SCSI子系统，NVMe驱动直接到块设备层。 关于SCSI子系统、NVMe的IO路径，可以参考这幅著名的Linux IO stack图。连接：Linux Storage Stack Diagram SCSI和ATA的转换这里有一个非常关键的知识点：在Linux内核里，除了NVMe以外，存储设备都是在SCSI体系内管理的。应用层的读写操作，会以bio的形式提交给block层，然后，block会把bio转换成request，并把该request加入到专为某个SCSI device服务的request queue中，接下来会有内核线程适时地从该queue中摘取request，并转换成SCSI cmd，再转换成ATA cmd，最终交由AHCI Controller（对于AHCI，实际上会把ATA cmd转换成FIS结构）发向硬盘执行。参考：request到ATA cmd的转换过程 我们接下来看看下发的SCSI的具体指令，打开scsi的日志信息，注意这里是-1。参考：Linux 开启 SCSI 日志调试功能12345scsi_logging_level 值可以在 boot 命令行设置也可以开启设备后在 /proc 文件系统中设置：-1 - Enable scsi events to syslog. // 开启所有scsi log0 - Disable scsi events to syslog. // 关闭所有scsi log命令: echo 0/-1 &gt; /proc/sys/dev/scsi/logging_level 我们知道sync命令就有刷盘的功能，执行一次再看看dmesg日志。这里下发了CDB 35H12345678[47505.162954] sd 0:0:0:0: [sda] tag#5 Send: scmd 0xffff97b61d238fc0[47505.162965] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00[47505.163957] sd 0:0:0:0: [sda] tag#5 Done: SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK[47505.163974] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00[47505.163985] sd 0:0:0:0: [sda] tag#5 scsi host busy 1 failed 0[47505.164003] sd 0:0:0:0: Notifying upper driver of completion (result 0)[47505.164013] sd 0:0:0:0: [sda] tag#5 sd_done: completed 0 of 0 bytes[47505.164023] sd 0:0:0:0: [sda] tag#5 0 sectors total, 0 bytes done. 在SCSI命令集里，35h指令对应的是SYNCHRONIZE CACHE，也就是刷盘。The SYNCHRONIZE CACHE (10) command (see table 199) requests that the device server ensure that the specified logical blocks have their most recent data values recorded in non-volatile cache and/or on the medium.参考：SCSI Commands Reference Manual 刷盘命令的转换SCSI的SYNCHRONIZE CACHE，ATA的FLUSH CACHE EXT，这是两条刷盘命令。我用的是SATA HDD/SSD，是在SCSI体系里使用ATA设备，刷盘命令也需要转换。通过搜索官方文档，可以看到libata-scsi.c里的ata_scsi_flush_xlat函数，就是做这个事。12345ata_scsi_flush_xlatTranslate SCSI SYNCHRONIZE CACHE commandDescriptionSets up an ATA taskfile to issue FLUSH CACHE or FLUSH CACHE EXT. 参考：The Linux driver implementer’s API guide » libATA Developer’s Guide 跟踪一下sync的在libata内核模块的执行路径，这里用到systemtap。在ata_scsi_queuecmd里，可以看到 SCSI cmd -&gt; ATA cmd -&gt; FIS 这个过程。1234567891011121314151617181920212223242526272829[root@MiWiFi-R1CM-srv ~]# cat libata.stp #!/usr/bin/stap -vprobe module(&quot;libata&quot;).function(&quot;*&quot;).call &#123; printf (&quot;Call : %s -&gt; %s\n&quot;, thread_indent(2) ,ppfunc())&#125;probe module(&quot;libata&quot;).function(&quot;*&quot;).return &#123; printf (&quot;Return: %s &lt;- %s\n&quot;, thread_indent(-2) ,ppfunc())&#125;[root@MiWiFi-R1CM-srv ~]# stap libata.stp Call : 0 sync(9551): -&gt; ata_scsi_queuecmdCall : 2 sync(9551): -&gt; ata_scsi_find_devCall : 3 sync(9551): -&gt; __ata_scsi_find_devCall : 4 sync(9551): -&gt; ata_find_devReturn: 5 sync(9551): &lt;- ata_find_devReturn: 6 sync(9551): &lt;- __ata_scsi_find_devReturn: 7 sync(9551): &lt;- ata_scsi_find_devCall : 8 sync(9551): -&gt; ata_qc_new_initReturn: 8 sync(9551): &lt;- ata_qc_new_initCall : 10 sync(9551): -&gt; ata_scsi_flush_xlatReturn: 11 sync(9551): &lt;- ata_scsi_flush_xlatCall : 12 sync(9551): -&gt; ata_std_qc_deferReturn: 13 sync(9551): &lt;- ata_std_qc_deferCall : 13 sync(9551): -&gt; ata_qc_issueCall : 14 sync(9551): -&gt; ata_tf_to_fisReturn: 15 sync(9551): &lt;- ata_tf_to_fisReturn: 16 sync(9551): &lt;- ata_qc_issueReturn: 17 sync(9551): &lt;- ata_scsi_queuecmd 查看ata_tf_to_fis函数的结构体tf-&gt;command，可以看到sync转换之后，发出的ATA CMD是EAh，也就是上一章里的FLUSH CACHE EXT (EAh) commands。12345678[root@MiWiFi-R1CM-srv ~]# cat ata_tf_to_fis.stp #!/usr/bin/stap -vprobe module(&quot;libata&quot;).function(&quot;ata_tf_to_fis&quot;).call &#123; printf (&quot;Call : %s -&gt; %s -&gt; %4x\n&quot;, thread_indent(0) ,ppfunc(), $tf-&gt;command)&#125;Call : 0 sync(10614): -&gt; ata_tf_to_fis -&gt; ea 至此，通过驱动层，我们知道，在SCSI子系统里，刷盘是SYNCHRONIZE CACHE这条SCSI命令，经过转换为ATA命令，发到磁盘上是FLUSH CACHE EXT。 块设备层文件系统层应用层1yum install man-pages.noarch 总结 带掉电保护的设备，不需要刷盘。 write cache enable时，不带掉电保护的设备，需要刷盘。 ATA标准是T13，刷盘命令是Flush cache ext，代码EAh。 SCSI标准是T10，刷盘命令是Synchronize Cache，代码35h。 bio转换成request，request转换成SCSI命令，SCSI命令转换为ATA命令，AHCI把ATA命令转换为FIS结构发向硬盘。 libata-scsi.c里的ata_scsi_flush_xlat函数进行刷盘命令从SCSI到ATA的转换。 参考在文章引用了很多文章，这里附上额外的一些参考，一并致谢。 In what sense does SATA “talk” SCSI? How much is shared between SCSI and ATA?]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>SCSI</tag>
        <tag>刷盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用wireguard打通内网机器和外网云服务器]]></title>
    <url>%2F2019%2F03%2F%E4%BD%BF%E7%94%A8wireguard%E6%89%93%E9%80%9A%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8%E5%92%8C%E5%A4%96%E7%BD%91%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[场景这是我个人的需求，但是也有借鉴意义。需要在外部连接家里的机器做测试，家里路由器拨号之后没有公网IP，所以使用一台具有公网IP的阿里云ECS服务器作为中转，打通内网的机器和阿里云服务器。在以往，我会使用strongswan来搭建IKEv2的VPN来实现这个需求，但是现在有更简单好用的wireguard了。 wireguard介绍毕竟是VPN软件，所以需要翻墙访问。wireguard官网wireguard官网的视频介绍 环境两台CentOS 7.6，都可以访问公网。A机器仅有内网IP，B机器有公网IP和内网IP。 配置方式1234567891011121314151617181920212223242526272829303132333435A机器(家里)内网(192.168.31.0/24)B机器(ECS)内网(172.16.100.0/24)分别在每个机器执行:yum install -y epel-releasecurl -Lo /etc/yum.repos.d/wireguard.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repoyum install wireguard-dkms wireguard-tools -ymkdir -p /etc/wireguardumask 077cd /etc/wireguardwg genkey | tee privatekey | wg pubkey &gt; publickeyvim wg0.conf 内容如下:[Interface]PrivateKey = 本机的privatekeyListenPort = 2503PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEPostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADEMTU = 1500[Peer]PublicKey = 远端的publickeyEndpoint = 远端的ip:2503（公网ip，至少需要一端有，没有就不写）AllowedIPs = 远端的网段启动systemctl start wg-quick@wg0.service echo &apos;net.ipv4.ip_forward = 1&apos; &gt;&gt; /etc/sysctl.conf 启用转发sysctl -p 分别A,B机器启动, 然后ping对方, 谁先ping, 谁就发起连接。由于我的环境里，只有阿里云ECS才有公网IP，所以我只能由家里机器发起ping。配置上开机启动服务。systemctl enable wg-quick@wg0.service 要开机自动连接到阿里云，就写个crontab的ping，每分钟ping一次好了。这里我使用家里的机器，ping阿里云服务器的内网IP，即可自动建立连接。123456789101112131415161718[root@MiWiFi-R1CM-srv ~]# cat /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed* * * * * root ping -c1 172.16.100.38 &amp;&gt; /dev/nullwg show 查看状态 由于wireguard是内核模块，需要注意内核各个rpm包小版本一致。例如我这里，都是3.10.0-957.5.1.el7.x86_64这个小版本。12345678[root@MiWiFi-R1CM-srv ~]# rpm -qa | grep kernelkernel-3.10.0-957.5.1.el7.x86_64kernel-headers-3.10.0-957.5.1.el7.x86_64kernel-tools-libs-3.10.0-957.5.1.el7.x86_64kernel-devel-3.10.0-957.5.1.el7.x86_64kernel-debuginfo-3.10.0-957.5.1.el7.x86_64kernel-tools-3.10.0-957.5.1.el7.x86_64kernel-debuginfo-common-x86_64-3.10.0-957.5.1.el7.x86_64]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VPN</tag>
        <tag>wireguard</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[纠正几个Linux的IO监控指标的误区]]></title>
    <url>%2F2019%2F03%2F%E7%BA%A0%E6%AD%A3%E5%87%A0%E4%B8%AALinux%E7%9A%84IO%E7%9B%91%E6%8E%A7%E6%8C%87%E6%A0%87%E7%9A%84%E8%AF%AF%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[前言本文主要面向初级工程师，假设你已经对的Linux性能监控工具有所了解，例如top、vmstat、mpstat、iostat等。 日常工作中，碰到IO性能问题是常有的事，本文主要探讨Linux下的IO监控里容易产生误区的点。 这些误区，一方面是因为工程师想当然，不仔细看文档，不理解底层细节。另一方面是因为Linux内核和监控工具的发展，落后于存储设备硬件的发展，软硬件发展存在脱节，因此监控工具不能反映硬件的真实情况。 纠正这些误区，对这些监控和背后原理理解越深刻，越能评估一个系统性能的真实情况，定位和解决问题也更容易。 环境12345678910Summary: ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4System: ASRock Z370M-ITX/acProcessors: 1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)Memory: 15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GBDisk: sda (scsi0): 240GB (0%) JBOD == 1 x LITEON-EGT-240N9SDisk: sdb: 100GB JBOD == 1 x INTEL-SSDSA2BZ100G3Disk: sdc (scsi2): 1.0TB JBOD == 1 x WDC-WD10JPLX-00MBPT1OS: CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.10.1.el7.x86_64 x86_64, 64-bitBIOS: AMI P1.50 11/16/2017Hostname: MiWiFi-R1CM-srv 这是一台普通的x86台式机，sdb是Intel SSD 710 Series，sdc是西数的7200转黑盘。使用这两块盘来做后面的实验。 正文下面介绍四个容易产生误区的指标，分别是%iowait、await、svctm、%util。顺序上会把%util放在svctm之前介绍。 %iowait 正确：%iowait（wa）是CPU的一种IDLE，%iowait大小不能用来反映IO瓶颈。 误区：（1）%iowait高，CPU很忙。（2）%iowait高，磁盘IO瓶颈。 解释%iowait（来自mpstat）和wa（来自top、vmstat）是同一个指标，表示在一个采样周期内，CPU空闲在等待未完成的IO请求所占的白分比。iowait的产生要满足两个条件，一是进程在等io，二是等io时没有进程可运行。 误区（1）%iowait高，CPU很忙。先看官方文档说明：123456man vmstatwa: Time spent waiting for IO. Prior to Linux 2.5.41, included in idle.man mpstat%iowaitShow the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. 文档已经明确显示，%iowait是一种IDLE，尤其在2.5.41以前的旧内核里，%iowait是直接统计在idle里的。既然%iowait的显示的百分比是一种IDLE，它是可以被其它进程使用的。%iowait高，CPU其实很闲，因为其它进程都在随眠。 实验验证12345678910111213141516171819202122232425262728293031323334353637383940414243在这台完全空闲的机器上，对sdc进行随机读，可以看到IOPS大约是60多，这与7200rpm的机械硬盘性能是相符的。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1fio-3.1Starting 1 threadJobs: 1 (f=1): [r(1)][6.7%][r=252KiB/s,w=0KiB/s][r=63,w=0 IOPS][eta 02m:48s]此时，我们看%iowait，可以看到在核心6上，100%的iowait。top - 22:27:51 up 3:08, 3 users, load average: 2.37, 2.40, 1.31Tasks: 157 total, 1 running, 156 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.0 us, 0.3 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 0.0 us, 0.3 sy, 0.0 ni, 0.0 id, 99.7 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11211948 free, 290604 used, 4431532 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14941848 avail Mem 这时，我们起一个stress打满CPU看看。[root@MiWiFi-R1CM-srv ~]# stress -c 6stress: info: [9856] dispatching hogs: 6 cpu, 0 io, 0 vm, 0 hdd可以看到，起了6个stress打满了6个核心，fio进程还在运行，但是%iowait已经被“吃掉”了，说明这部分IDLE的CPU时间片已经被stress征用了。top - 22:28:36 up 3:09, 3 users, load average: 3.63, 2.67, 1.45Tasks: 162 total, 7 running, 155 sleeping, 0 stopped, 0 zombie%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 99.7 us, 0.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 99.7 us, 0.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11208508 free, 293992 used, 4431584 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14938420 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 9857 root 20 0 7308 96 0 R 100.0 0.0 0:22.69 stress 9861 root 20 0 7308 96 0 R 100.0 0.0 0:22.71 stress 9862 root 20 0 7308 96 0 R 100.0 0.0 0:22.71 stress 9858 root 20 0 7308 96 0 R 99.7 0.0 0:22.67 stress 9859 root 20 0 7308 96 0 R 99.7 0.0 0:22.68 stress 9860 root 20 0 7308 96 0 R 99.7 0.0 0:22.70 stress 9834 root 20 0 1091604 293556 261636 S 0.3 1.8 0:01.06 fio 误区（2）%iowait高，磁盘IO瓶颈。由之前的解释可以看到，这个指标是描述CPU的IDLE的，它与磁盘IO是否到达瓶颈一点关系都没有，它都不是一个用来描述磁盘IO性能的指标。 实验验证1234567891011121314151617181920212223242526272829303132333435363738394041这个实验使用ssd，如下fio命令，在6个进程下，ssd的随机读性能是25k iops，%iowait超过80%。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 6 threadsJobs: 6 (f=6): [r(6)][20.0%][r=97.0MiB/s,w=0KiB/s][r=25.1k,w=0 IOPS][eta 02m:24s] top - 22:45:45 up 3:26, 3 users, load average: 4.68, 2.59, 1.81Tasks: 158 total, 1 running, 157 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.7 us, 6.7 sy, 0.0 ni, 3.4 id, 89.2 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 1.3 us, 6.4 sy, 0.0 ni, 1.3 id, 91.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 1.3 us, 7.0 sy, 0.0 ni, 3.7 id, 88.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.7 us, 7.0 sy, 0.0 ni, 2.0 id, 90.3 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 1.3 us, 6.7 sy, 0.0 ni, 1.3 id, 90.6 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 1.7 us, 7.3 sy, 0.0 ni, 5.2 id, 83.3 wa, 0.0 hi, 2.6 si, 0.0 stKiB Mem : 15934084 total, 11223276 free, 278992 used, 4431816 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14953420 avail Mem 还是这块盘，ioengine我们从psync改成aio，同时把iodepth从1改成了8，可以看到44k的IOPS，但是%iowait却是0。这里说明，%iowait大小与磁盘瓶颈毫无关系，由于aio是异步的，CPU不需要IDLE等待IO，也就不会产生%iowait。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4krand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8...fio-3.1Starting 6 threadsJobs: 6 (f=6): [r(6)][5.6%][r=173MiB/s,w=0KiB/s][r=44.2k,w=0 IOPS][eta 02m:50s]top - 22:49:31 up 3:30, 3 users, load average: 1.14, 2.61, 2.06Tasks: 156 total, 1 running, 155 sleeping, 0 stopped, 0 zombie%Cpu0 : 3.0 us, 4.0 sy, 0.0 ni, 93.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 2.0 us, 3.0 sy, 0.0 ni, 95.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.3 us, 0.7 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu5 : 5.8 us, 6.9 sy, 0.0 ni, 87.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 15934084 total, 11219948 free, 282280 used, 4431856 buff/cacheKiB Swap: 8061948 total, 8061948 free, 0 used. 14950088 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 10091 root 20 0 1431564 281112 261664 S 33.6 1.8 0:26.54 fio await 正确：表示IO从创建到完成的平均时间，包含IO排队时间+存储设备处理时间。 误区：（1）混淆%iowait和await。（2）认为await高等于磁盘慢。 解释await是iostat里的指标，iostat属于sysstat这个rpm包。await表示平均每个IO所需要的时间，包括在队列等待的时间，也包括磁盘控制器处理本次请求的有效时间。123456789man iostatawaitThe average time (in milliseconds) for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them.这里借用blktrace的blkparse显示的各指标点，await是从IO到达block层开始算起，包含排队时间，到最后IO完毕。Q-------&gt;G------------&gt;I---------&gt;M-------------------&gt;D-----------------------------&gt;C|-Q time-|-Insert time-||--------- merge time ------------|-merge with other IO||----------------scheduler time time-------------------|---driver,adapter,storagetime--| 误区（1）混淆%iowait和await。在工作中，我遇到过几次运维和研发人员混淆这两个概念的，弄清楚并在表述的时候注意即可。 误区（2）认为await高等于磁盘慢。await包含了队列时间，我们只需要保持磁盘压力不变的情况下，增加队列深度即可验证这个问题。 实验验证1234567891011121314151617181920212223这里，我们限制IOPS为100，先用队列深度8，可以看到await 80。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8fio-3.1Starting 1 threadJobs: 1 (f=1), 0-100 IOPS: [r(1)][5.6%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:50s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 97.00 0.00 0.38 0.00 8.00 8.00 84.79 84.79 0.00 10.31 100.00sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00还是限制IOPS为100，队列深度调高到16，可以看到，IOPS不变的情况下，await增加到110左右。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 16 -thread -rw=randread -ioengine=libaio -bs=4k -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16fio-3.1Starting 1 threadJobs: 1 (f=1), 0-100 IOPS: [r(1)][8.3%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:45s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 101.00 0.00 0.39 0.00 8.00 11.93 109.34 109.34 0.00 9.86 99.60sdb 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 %util 正确：iostat里的%util并不能准确反映存储设备使用率（或者称为饱和率）。 误区：%util就是存储设备硬件的使用率，达到100%时就到磁盘瓶颈了。 解释%util估算了一个使用率，但是存储设备的使用率以及是否饱和，是没有接口告诉Linux系统的。%util通过/proc/diskstats计算得到，不关心等待在队里里面IO的个数，它只关心队列中有没有IO。。整个计算方式把存储设备当做只能串行处理IO的磁盘，当使用支持并发处理IO的存储设备时，此项就不准确了。当%util是100%时，代表Linux队列里一直有IO，但不能代表硬件存储设备已经饱和。123456在sysstat网站的最新文档中也已经注明： But for devices serving requests in parallel, such as RAID arrays and modern SSDs, this number does not reflect their performance limits.文档地址：http://sebastien.godard.pagesperso-orange.fr/man_iostat.html%utilPercentage of elapsed time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100%. 实验验证由于%util是以单并发的存储设备设计的，只要是支持多并发的存储设备，%util就不准确了。提升并发数，即可验证这个问题。12345678910111213141516171819202122232425同样的测试用例，我们num-jobs从4改到8，可以看到，使用率都是100%，但是IOPS有巨大的不同。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 4 threadsJobs: 4 (f=4): [r(4)][3.3%][r=74.7MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:54s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 18078.00 0.00 70.62 0.00 8.00 3.57 0.20 0.20 0.00 0.06 100.00[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=8 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 8 threadsJobs: 8 (f=8): [r(8)][7.8%][r=110MiB/s,w=0KiB/s][r=28.2k,w=0 IOPS][eta 02m:46s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 28233.00 0.00 110.29 0.00 8.00 7.31 0.26 0.26 0.00 0.04 100.00 svctm 正确：iostat里的svctm并不能准确反映存储设备的处理时间。 误区：svctm就是存储设备硬件处理IO的时间。 解释从官方文档可以看到，Do not trust this field any more.实际上，iostat获取这个svctm仅是通过一个简单计算。iostat计算svctm需要使用%util，但%util在多并发IO里，本身就是不准确的，所以间接造成svctm也不准确。12svctmThe average service time (in milliseconds) for I/O requests that were issued to the device. Warning! Do not trust this field any more. This field will be removed in a future sysstat version. 实验验证对于相同的IO模型，存储设备的处理时间都应该是一样的。如果压力越大，存储设备处理时间应该越长才对。我们验证svctm是否和真实情况一样。123456789101112131415161718192021222324我们使用SSD做实验，可以看到，当从4个并发提升到32个并发时，IOPS从19k提升到44k，但是svctm却从0.05ms下降到0.02ms，明显不符合现实。[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 4 threadsJobs: 4 (f=4): [r(4)][5.0%][r=74.6MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:51s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 19069.00 0.00 74.49 0.00 8.00 3.90 0.20 0.20 0.00 0.05 100.00[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -runtime=180 -group_reporting -numjobs=32 -name=rand_100read_4k rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1...fio-3.1Starting 32 threadsJobs: 32 (f=32): [r(32)][31.7%][r=172MiB/s,w=0KiB/s][r=44.1k,w=0 IOPS][eta 02m:03s]Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdc 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00sdb 0.00 0.00 44080.00 0.00 172.19 0.00 8.00 31.37 0.71 0.71 0.00 0.02 100.00 总结 %iowait并没有提供什么有效信息，因为它是描述IDLE的。 %iowait大小受CPU的负载变化而变化，这个指标如果很大，除了能说明CPU很闲在等待IO以外，并不能反映IO压力或者瓶颈。另外，aio不会使CPU产生%iowait。 iostat提供了基本的监控数据，但是分析IO瓶颈，关键是去看Linux的IO的监控指标是否打满了存储设备的真实性能，因此必须对存储设备在当前IO模型下具备的真实性能有所了解。 这些值虽然不够准确，但是在生产环境中，仍然具备参考意义：当你的业务类型和压力没有任何变化时，如果这些值偏离了基线（baseline）或者历史平均值，则你需要去排查是否哪里出了问题。 参考资料本文讲解并不深入，更多的是实验思路。建议阅读下列文章，包含原理性的解释，一并致谢：朱辉(茶水)： Linux Kernel iowait 时间的代码原理 深入理解iostat 辩证看待 iostat 深入理解磁盘IO利用率及饱和度]]></content>
      <categories>
        <category>性能分析</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>性能监控</tag>
      </tags>
  </entry>
</search>
