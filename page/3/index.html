<!DOCTYPE html>




<html class="theme-next gemini" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="个人小站。致力于为运维及研发提供准确、靠谱的运维资料和经验。">
<meta name="keywords" content="运维、DevOPS、性能、体系、架构、x86">
<meta property="og:type" content="website">
<meta property="og:title" content="运维深处">
<meta property="og:url" content="http://blog.zw1m.com/page/3/index.html">
<meta property="og:site_name" content="运维深处">
<meta property="og:description" content="个人小站。致力于为运维及研发提供准确、靠谱的运维资料和经验。">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="运维深处">
<meta name="twitter:description" content="个人小站。致力于为运维及研发提供准确、靠谱的运维资料和经验。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.zw1m.com/page/3/">





  <title>运维深处</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">运维深处</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">底层技术与最佳实践</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.zw1m.com/2019/03/全链路分析数据落盘机制-硬件及驱动层/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Roger K">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="运维深处">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/全链路分析数据落盘机制-硬件及驱动层/" itemprop="url">全链路分析数据落盘机制-硬件及驱动层</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-27T10:30:40+08:00">
                2019-03-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/体系结构/" itemprop="url" rel="index">
                    <span itemprop="name">体系结构</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>数据落盘，顾名思义，就是数据写入最终的非易失（Non-volatile）的存储介质，例如HDD（磁性介质）、SSD（半导体介质）等，当服务器故障或异常掉电时，数据做到不丢失。<br>由于硬件故障是经常发生的，对数据安全性要求高的场景，例如金融类的数据库、日志、消息等，数据落盘非常重要，有时甚至是一个企业的底线。<br>本文尝试从底层硬件开始，向上逐层讲到应用，来说明数据落盘的路径，以及如何保证数据落盘，并且重点放在实验验证。</p>
<h4 id="重点问题及知识点"><a href="#重点问题及知识点" class="headerlink" title="重点问题及知识点"></a>重点问题及知识点</h4><ul>
<li>当应用发起写入数据的请求返回OK时，数据是否真的到达了磁盘，有哪些因素在起作用？</li>
<li>应用程序的写入参数、文件系统参数、硬件参数是如何保证数据落盘的？</li>
<li>今天的x86硬件体系结构，服务器硬件层面，有哪些硬件write cache，断电是否数据丢失？</li>
<li>数据落盘，很重要的“刷盘”命令，硬件层面到底是什么？</li>
<li>掉电保护和“刷盘”的关系是什么，是否就不用“刷盘”了？</li>
<li>SCSI和ATA到底是什么关系，为什么我用的SATA盘识别成SCSI设备？</li>
</ul>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p>还是我的这台机器，sdb是SATA SSD，sdc是SATA HDD。它们连接在PCH（南桥），走AHCI控制器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Summary:	ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4</span><br><span class="line">System:		ASRock Z370M-ITX/ac</span><br><span class="line">Processors:	1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)</span><br><span class="line">Memory:		15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GB</span><br><span class="line">Disk:		sda (scsi0): 240GB (7%) JBOD == 1 x 240GB Gen3 signaling speed (6.0Gb/s) LITEON-EGT-240N9S</span><br><span class="line">Disk:		sdb: 100GB JBOD == 1 x 100GB SATA 300MB/s INTEL-SSDSA2BZ100G3</span><br><span class="line">Disk:		sdc (scsi2): 1.0TB JBOD == 1 x 1.0TB Gen3 signaling speed (6.0Gb/s) WDC-WD10JPLX-00MBPT1</span><br><span class="line">Disk-Control:	ahci0: Intel 200 Series PCH SATA controller [AHCI mode]</span><br><span class="line">Network:	00:1f.6 (e1000e0): Intel Ethernet Connection (2) I219-V</span><br><span class="line">Network:	02:00.0 (igb0): Intel I211 Gigabit</span><br><span class="line">Network:	03:00.0 (iwlwifi0): Intel Dual Band Wireless-AC 3168NGW [Stone Peak]</span><br><span class="line">OS:		CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.5.1.el7.x86_64 x86_64, 64-bit</span><br><span class="line">BIOS:		AMI P1.50 11/16/2017</span><br><span class="line">Hostname:	MiWiFi-R1CM-srv</span><br></pre></td></tr></table></figure></p>
<h3 id="硬件层"><a href="#硬件层" class="headerlink" title="硬件层"></a>硬件层</h3><h4 id="硬件存储体系简述"><a href="#硬件存储体系简述" class="headerlink" title="硬件存储体系简述"></a>硬件存储体系简述</h4><p>在x86服务器上，本地存储介质的连接方式主要有以下几种，<-> 表示互相连接。</-></p>
<ul>
<li>内存 <-> CPU <-> Raid/HBA卡 <-> SATA/SAS HDD/SSD</-></-></-></li>
<li>内存 <-> CPU <-> PCH <-> SATA HDD/SSD</-></-></-></li>
<li>内存 <-> CPU <-> PCIe/NVMe SSD</-></-></li>
</ul>
<p>CPU包含内存控制器，直连内存。内存一般存放应用自身维护的cache和系统的page cache，内存当然是掉电数据丢失的。<br>为了提升性能，Raid卡、HDD、SSD都有自身的write cache，这些write cache是影响落盘的硬件层面因素。</p>
<h4 id="HDD-SSD-write-cache"><a href="#HDD-SSD-write-cache" class="headerlink" title="HDD/SSD write cache"></a>HDD/SSD write cache</h4><p>这里简单测试一下就好。我们可以用hdparm来查看、关闭、打开write cache。<br>这里少于ms级的数据写入时间，明显是HDD的write cache的返回。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ata]# hdparm -W /dev/sdc</span><br><span class="line">/dev/sdc:</span><br><span class="line"> write-caching =  1 (on)</span><br><span class="line"></span><br><span class="line">[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct</span><br><span class="line">记录了1+0 的读入</span><br><span class="line">记录了1+0 的写出</span><br><span class="line">4096字节(4.1 kB)已复制，0.000929063 秒，4.4 MB/秒</span><br></pre></td></tr></table></figure></p>
<p>可以看到，关闭HDD cache对写入的延迟影响是巨大的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ata]# hdparm -W 0 /dev/sdc</span><br><span class="line">/dev/sdc:</span><br><span class="line"> setting drive write-caching to 0 (off)</span><br><span class="line"> write-caching =  0 (off)</span><br><span class="line"></span><br><span class="line">[root@MiWiFi-R1CM-srv ata]# dd if=/dev/zero of=/dev/sdc count=1 bs=4k oflag=direct</span><br><span class="line">记录了1+0 的读入</span><br><span class="line">记录了1+0 的写出</span><br><span class="line">4096字节(4.1 kB)已复制，0.042402 秒，96.6 kB/秒</span><br></pre></td></tr></table></figure></p>
<h4 id="刷盘指令"><a href="#刷盘指令" class="headerlink" title="刷盘指令"></a>刷盘指令</h4><p>由于write cache enable后，掉电数据丢失，为了保证数据落盘，也就引出了刷盘命令。<br>简单的说，刷盘是把HDD/SSD write cache里的数据写入存储介质（碟片/Nand），数据写入完毕后，再返回OK。</p>
<p>可以参考wikipedia关于刷盘的介绍。</p>
<p><a href="https://en.wikipedia.org/wiki/Disk_buffer" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Disk_buffer</a><br>Cache flushing<br>Data that was accepted in write cache of a disk device will be eventually written to disk platters, provided that no starvation condition occurs as a result of firmware flaw, and that disk power supply is not interrupted before cached writes are forced to disk platters. In order to control write cache, ATA specification included FLUSH CACHE (E7h) and FLUSH CACHE EXT (EAh) commands. These commands cause the disk to complete writing data from its cache, and disk will return good status after data in the write cache is written to disk media. In addition, flushing the cache can be initiated at least to some disks by issuing Soft reset or Standby (Immediate) command.[4]</p>
<p>在ATA Command Set里，定义了FLUSH CACHE (E7h) 和 FLUSH CACHE EXT (EAh) 这两个指令用于刷盘。<br>这里FLUSH_CACHE是用于支持28bit LBA长度的命令的存储设备的，最大137GB硬盘，目前已经淘汰。<br>今天的刷盘命令，都是指FLUSH_CACHE_EXT，即48bit LBA长度的命令。<br>我们可以看看行业规范如何定义这个命令：</p>
<p>The FLUSH CACHE EXT command requests the device to flush the volatile write cache. If there is data in the volatile write cache, that data shall be written to the non-volatile media. This command shall not indicate completion until the data is flushed to the non-volatile media or an error occurs. If the volatile write cache is disabled or no volatile write cache is present, the device shall indicate command completion without error.</p>
<p>链接：<a href="http://www.t13.org/documents/UploadedDocuments/docs2016/di529r14-ATAATAPI_Command_Set_-_4.pdf" target="_blank" rel="noopener">ATAATAPI_Command_Set</a></p>
<h4 id="掉电保护"><a href="#掉电保护" class="headerlink" title="掉电保护"></a>掉电保护</h4><p>刷盘这个指令当时是为了解决HDD掉电write cache数据一定丢失的问题，在Nand介质出现以后，引入了掉电数据保护功能。<br>掉电数据保护 power loss protection (PLP)，指的是服务器异常断电时，存储设备能把write cache里的数据写回介质。<br>以下总结适用于普通的x86服务器，以下都是Write cache enable场景。</p>
<ul>
<li>企业级SSD、包含SATA/SAS/PCIe/NVMe SSD等，通过超级电容保证断电时把write cache中的数据写回Nand。</li>
<li>消费级SSD由于面向的客户群体及成本考虑，不带掉电数据保护，掉电时cache数据存在丢失几率。</li>
<li>HDD，无论企业级还是消费级，都不带掉电保护功能。因为驱动12V和5V的马达保证转速并写入数据对功率要求较大。</li>
<li>Raid卡一般配置电池或超级电容，断电后把write cache的数据临时写入Raid卡的板载Nand颗粒上。当服务器上电后，Raid卡重新把Nand的数据写回HDD。当使用Raid卡时，Raid卡默认关闭HDD的write cache，避免Raid卡不丢数据，但是HDD丢数据。</li>
</ul>
<h4 id="什么时候不用刷盘"><a href="#什么时候不用刷盘" class="headerlink" title="什么时候不用刷盘"></a>什么时候不用刷盘</h4><p>由上文可知，支持掉电保护的硬件，是不需要刷盘的。例如：</p>
<ul>
<li>数据到达带电池/超级电容的Raid卡write cache，即向上层返回写入OK，可以认为数据落盘（默认关闭HDD write cache）。</li>
<li>没有raid卡，数据到达企业级SSD的write cache，即向上层返回写入OK，可以认为数据落盘。</li>
</ul>
<p>你的设备是否支持掉电保护，请以你实际的硬件设备为准，在引入生产之前，查看供应商的测试报告和自己进行测试。</p>
<h4 id="什么时候需要刷盘"><a href="#什么时候需要刷盘" class="headerlink" title="什么时候需要刷盘"></a>什么时候需要刷盘</h4><p>如果不支持掉电保护同时write cache enable，就需要刷盘，也就是下发FLUSH_CACHE_EXT，并等待这条指令返回OK，才可以认为数据落盘。</p>
<h3 id="驱动层"><a href="#驱动层" class="headerlink" title="驱动层"></a>驱动层</h3><p>在硬件（包含硬件firmware）之上，就是驱动层了，由于我用的是SATA HDD/SSD，ATA驱动是SCSI子系统的一部分，所以这里重点看SCSI子系统如何下发FLUSH_CACHE_EXT命令。如果你使用的是PCIe/NVMe SSD，则不经过SCSI子系统，NVMe驱动直接到块设备层。</p>
<p>关于SCSI子系统、NVMe的IO路径，可以参考这幅著名的Linux IO stack图。<br>连接：<a href="https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram" target="_blank" rel="noopener">Linux Storage Stack Diagram
</a></p>
<h4 id="SCSI和ATA的转换"><a href="#SCSI和ATA的转换" class="headerlink" title="SCSI和ATA的转换"></a>SCSI和ATA的转换</h4><p>这里有一个非常关键的知识点：在Linux内核里，除了NVMe以外，存储设备都是在SCSI体系内管理的。应用层的读写操作，会以bio的形式提交给block层，然后，block会把bio转换成request，并把该request加入到专为某个SCSI device服务的request queue中，接下来会有内核线程适时地从该queue中摘取request，并转换成SCSI cmd，再转换成ATA cmd，最终交由AHCI Controller（对于AHCI，实际上会把ATA cmd转换成FIS结构）发向硬盘执行。<br>参考：<a href="http://www.cnblogs.com/raymondpang/articles/4469500.html" target="_blank" rel="noopener">request到ATA cmd的转换过程</a></p>
<p>我们接下来看看下发的SCSI的具体指令，打开scsi的日志信息，注意这里是-1。<br>参考：<a href="https://blog.csdn.net/fhqfghgdx1993/article/details/79915918" target="_blank" rel="noopener">Linux 开启 SCSI 日志调试功能</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scsi_logging_level 值可以在 boot 命令行设置也可以开启设备后在 /proc 文件系统中设置：</span><br><span class="line">-1   - Enable scsi events to syslog.         // 开启所有scsi log</span><br><span class="line">0    - Disable scsi events to syslog.        // 关闭所有scsi log</span><br><span class="line">命令:</span><br><span class="line">    echo 0/-1 &gt; /proc/sys/dev/scsi/logging_level</span><br></pre></td></tr></table></figure></p>
<p>我们知道sync命令就有刷盘的功能，执行一次再看看dmesg日志。这里下发了CDB 35H<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[47505.162954] sd 0:0:0:0: [sda] tag#5 Send: scmd 0xffff97b61d238fc0</span><br><span class="line">[47505.162965] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00</span><br><span class="line">[47505.163957] sd 0:0:0:0: [sda] tag#5 Done: SUCCESS Result: hostbyte=DID_OK driverbyte=DRIVER_OK</span><br><span class="line">[47505.163974] sd 0:0:0:0: [sda] tag#5 CDB: Synchronize Cache(10) 35 00 00 00 00 00 00 00 00 00</span><br><span class="line">[47505.163985] sd 0:0:0:0: [sda] tag#5 scsi host busy 1 failed 0</span><br><span class="line">[47505.164003] sd 0:0:0:0: Notifying upper driver of completion (result 0)</span><br><span class="line">[47505.164013] sd 0:0:0:0: [sda] tag#5 sd_done: completed 0 of 0 bytes</span><br><span class="line">[47505.164023] sd 0:0:0:0: [sda] tag#5 0 sectors total, 0 bytes done.</span><br></pre></td></tr></table></figure></p>
<p>在SCSI命令集里，35h指令对应的是SYNCHRONIZE CACHE，也就是刷盘。<br>The SYNCHRONIZE CACHE (10) command (see table 199) requests that the device server ensure that the specified logical blocks have their most recent data values recorded in non-volatile cache and/or on the medium.<br>参考：<a href="https://www.seagate.com/files/staticfiles/support/docs/manual/Interface%20manuals/100293068k.pdf" target="_blank" rel="noopener">SCSI Commands Reference Manual</a></p>
<h4 id="刷盘命令的转换"><a href="#刷盘命令的转换" class="headerlink" title="刷盘命令的转换"></a>刷盘命令的转换</h4><p>SCSI的SYNCHRONIZE CACHE，ATA的FLUSH CACHE EXT，这是两条刷盘命令。<br>我用的是SATA HDD/SSD，是在SCSI体系里使用ATA设备，刷盘命令也需要转换。<br>通过搜索官方文档，可以看到libata-scsi.c里的ata_scsi_flush_xlat函数，就是做这个事。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ata_scsi_flush_xlat</span><br><span class="line">Translate SCSI SYNCHRONIZE CACHE command</span><br><span class="line"></span><br><span class="line">Description</span><br><span class="line">Sets up an ATA taskfile to issue FLUSH CACHE or FLUSH CACHE EXT.</span><br></pre></td></tr></table></figure></p>
<p>参考：<a href="https://www.kernel.org/doc/html/latest/driver-api/libata.html#c.ata_scsi_flush_xlat" target="_blank" rel="noopener">The Linux driver implementer’s API guide » libATA Developer’s Guide</a></p>
<p>跟踪一下sync的在libata内核模块的执行路径，这里用到systemtap。<br>在ata_scsi_queuecmd里，可以看到 SCSI cmd -&gt; ATA cmd -&gt; FIS 这个过程。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ~]# cat libata.stp </span><br><span class="line">#!/usr/bin/stap -v</span><br><span class="line"></span><br><span class="line">probe module(&quot;libata&quot;).function(&quot;*&quot;).call &#123;</span><br><span class="line">    printf (&quot;Call  : %s -&gt; %s\n&quot;, thread_indent(2) ,ppfunc())</span><br><span class="line">&#125;</span><br><span class="line">probe module(&quot;libata&quot;).function(&quot;*&quot;).return &#123;</span><br><span class="line">    printf (&quot;Return: %s &lt;- %s\n&quot;, thread_indent(-2) ,ppfunc())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# stap libata.stp </span><br><span class="line">Call  :      0 sync(9551):  -&gt; ata_scsi_queuecmd</span><br><span class="line">Call  :      2 sync(9551):    -&gt; ata_scsi_find_dev</span><br><span class="line">Call  :      3 sync(9551):      -&gt; __ata_scsi_find_dev</span><br><span class="line">Call  :      4 sync(9551):        -&gt; ata_find_dev</span><br><span class="line">Return:      5 sync(9551):        &lt;- ata_find_dev</span><br><span class="line">Return:      6 sync(9551):      &lt;- __ata_scsi_find_dev</span><br><span class="line">Return:      7 sync(9551):    &lt;- ata_scsi_find_dev</span><br><span class="line">Call  :      8 sync(9551):    -&gt; ata_qc_new_init</span><br><span class="line">Return:      8 sync(9551):    &lt;- ata_qc_new_init</span><br><span class="line">Call  :     10 sync(9551):    -&gt; ata_scsi_flush_xlat</span><br><span class="line">Return:     11 sync(9551):    &lt;- ata_scsi_flush_xlat</span><br><span class="line">Call  :     12 sync(9551):    -&gt; ata_std_qc_defer</span><br><span class="line">Return:     13 sync(9551):    &lt;- ata_std_qc_defer</span><br><span class="line">Call  :     13 sync(9551):    -&gt; ata_qc_issue</span><br><span class="line">Call  :     14 sync(9551):      -&gt; ata_tf_to_fis</span><br><span class="line">Return:     15 sync(9551):      &lt;- ata_tf_to_fis</span><br><span class="line">Return:     16 sync(9551):    &lt;- ata_qc_issue</span><br><span class="line">Return:     17 sync(9551):  &lt;- ata_scsi_queuecmd</span><br></pre></td></tr></table></figure></p>
<p>查看ata_tf_to_fis函数的结构体tf-&gt;command，可以看到sync转换之后，发出的ATA CMD是EAh，也就是上一章里的FLUSH CACHE EXT (EAh) commands。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ~]# cat ata_tf_to_fis.stp </span><br><span class="line">#!/usr/bin/stap -v</span><br><span class="line"></span><br><span class="line">probe module(&quot;libata&quot;).function(&quot;ata_tf_to_fis&quot;).call &#123;</span><br><span class="line">    printf (&quot;Call  : %s -&gt; %s -&gt; %4x\n&quot;, thread_indent(0) ,ppfunc(), $tf-&gt;command)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Call  :      0 sync(10614): -&gt; ata_tf_to_fis -&gt;   ea</span><br></pre></td></tr></table></figure></p>
<p>至此，通过驱动层，我们知道，在SCSI子系统里，刷盘是SYNCHRONIZE CACHE这条SCSI命令，经过转换为ATA命令，发到磁盘上是FLUSH CACHE EXT。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>带掉电保护的设备，不需要刷盘。</li>
<li>write cache enable时，不带掉电保护的设备，需要刷盘。</li>
<li>ATA标准是T13，刷盘命令是Flush cache ext，代码EAh。</li>
<li>SCSI标准是T10，刷盘命令是Synchronize Cache，代码35h。</li>
<li>bio转换成request，request转换成SCSI命令，SCSI命令转换为ATA命令，AHCI把ATA命令转换为FIS结构发向硬盘。</li>
<li>libata-scsi.c里的ata_scsi_flush_xlat函数进行刷盘命令从SCSI到ATA的转换。</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>本文引用了很多文章，这里附上额外的一些参考，一并致谢。</p>
<p><a href="https://unix.stackexchange.com/questions/144561/in-what-sense-does-sata-talk-scsi-how-much-is-shared-between-scsi-and-ata" target="_blank" rel="noopener">In what sense does SATA “talk” SCSI? How much is shared between SCSI and ATA?</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.zw1m.com/2019/03/使用wireguard打通内网机器和外网云服务器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Roger K">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="运维深处">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/使用wireguard打通内网机器和外网云服务器/" itemprop="url">使用wireguard打通内网机器和外网云服务器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-22T19:37:13+08:00">
                2019-03-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/网络/" itemprop="url" rel="index">
                    <span itemprop="name">网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><p>这是我个人的需求，但是也有借鉴意义。<br>需要在外部连接家里的机器做测试，家里路由器拨号之后没有公网IP，所以使用一台具有公网IP的阿里云ECS服务器作为中转，打通内网的机器和阿里云服务器。<br>在以往，我会使用strongswan来搭建IKEv2的VPN来实现这个需求，但是现在有更简单好用的wireguard了。</p>
<h3 id="wireguard介绍"><a href="#wireguard介绍" class="headerlink" title="wireguard介绍"></a>wireguard介绍</h3><p>毕竟是VPN软件，所以需要翻墙访问。<br><a href="https://www.wireguard.com/" target="_blank" rel="noopener">wireguard官网</a><br><a href="https://www.wireguard.com/presentations/" target="_blank" rel="noopener">wireguard官网的视频介绍</a></p>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p>两台CentOS 7.6，都可以访问公网。<br>A机器仅有内网IP，B机器有公网IP和内网IP。</p>
<h3 id="配置方式"><a href="#配置方式" class="headerlink" title="配置方式"></a>配置方式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">A机器(家里)内网(192.168.31.0/24)</span><br><span class="line">B机器(ECS)内网(172.16.100.0/24)</span><br><span class="line"></span><br><span class="line">分别在每个机器执行:</span><br><span class="line">yum install -y epel-release</span><br><span class="line">curl -Lo /etc/yum.repos.d/wireguard.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repo</span><br><span class="line"></span><br><span class="line">yum install wireguard-dkms wireguard-tools -y</span><br><span class="line">mkdir -p  /etc/wireguard</span><br><span class="line">umask 077</span><br><span class="line">cd  /etc/wireguard</span><br><span class="line">wg genkey | tee privatekey | wg pubkey &gt; publickey</span><br><span class="line">vim wg0.conf 内容如下:</span><br><span class="line"></span><br><span class="line">[Interface]</span><br><span class="line">PrivateKey = 本机的privatekey</span><br><span class="line">ListenPort = 2503</span><br><span class="line">PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">MTU = 1500</span><br><span class="line">[Peer]</span><br><span class="line">PublicKey = 远端的publickey</span><br><span class="line">Endpoint = 远端的ip:2503（公网ip，至少需要一端有，没有就不写）</span><br><span class="line">AllowedIPs = 远端的网段</span><br><span class="line"></span><br><span class="line">启动</span><br><span class="line">systemctl start wg-quick@wg0.service </span><br><span class="line">echo &apos;net.ipv4.ip_forward = 1&apos;  &gt;&gt; /etc/sysctl.conf </span><br><span class="line">启用转发</span><br><span class="line">sysctl -p </span><br><span class="line"></span><br><span class="line">分别A,B机器启动, 然后ping对方, 谁先ping, 谁就发起连接。</span><br><span class="line">由于我的环境里，只有阿里云ECS才有公网IP，所以我只能由家里机器发起ping。</span><br><span class="line">配置上开机启动服务。</span><br><span class="line">systemctl enable wg-quick@wg0.service</span><br></pre></td></tr></table></figure>
<p>要开机自动连接到阿里云，就写个crontab的ping，每分钟ping一次好了。<br>这里我使用家里的机器，ping阿里云服务器的内网IP，即可自动建立连接。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ~]# cat /etc/crontab </span><br><span class="line">SHELL=/bin/bash</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=</span><br><span class="line"></span><br><span class="line"># For details see man 4 crontabs</span><br><span class="line"></span><br><span class="line"># Example of job definition:</span><br><span class="line"># .---------------- minute (0 - 59)</span><br><span class="line"># |  .------------- hour (0 - 23)</span><br><span class="line"># |  |  .---------- day of month (1 - 31)</span><br><span class="line"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="line"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="line"># |  |  |  |  |</span><br><span class="line"># *  *  *  *  * user-name  command to be executed</span><br><span class="line">*  *  *  *  * root  ping -c1 172.16.100.38 &amp;&gt; /dev/null</span><br><span class="line"></span><br><span class="line">wg show 查看状态</span><br></pre></td></tr></table></figure></p>
<p>由于wireguard是内核模块，需要注意内核各个rpm包小版本一致。<br>例如我这里，都是3.10.0-957.5.1.el7.x86_64这个小版本。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@MiWiFi-R1CM-srv ~]# rpm -qa | grep kernel</span><br><span class="line">kernel-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-headers-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-tools-libs-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-devel-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-debuginfo-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-tools-3.10.0-957.5.1.el7.x86_64</span><br><span class="line">kernel-debuginfo-common-x86_64-3.10.0-957.5.1.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<h3 id="解决ssh长输出变卡"><a href="#解决ssh长输出变卡" class="headerlink" title="解决ssh长输出变卡"></a>解决ssh长输出变卡</h3><p>从远程通过wireguard vpn连接到本地机器时，ssh之后敲命令正常，但是长输出命令就会卡住，例如dmesg。<br>这种问题是由于MTU造成的丢包重传延迟。<br>把cat /etc/wireguard/wg0.conf配置文件里的MTU =1500设置小一点，例如1400，我这边问题解决，dmesg命令秒开。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.zw1m.com/2019/03/纠正几个Linux的IO监控指标的误区/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Roger K">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="运维深处">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/纠正几个Linux的IO监控指标的误区/" itemprop="url">纠正几个Linux的IO监控指标的误区</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-19T14:37:50+08:00">
                2019-03-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/性能分析/" itemprop="url" rel="index">
                    <span itemprop="name">性能分析</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文主要面向初级工程师，假设你已经对的Linux性能监控工具有所了解，例如top、vmstat、mpstat、iostat等。</p>
<p>日常工作中，碰到IO性能问题是常有的事，本文主要探讨Linux下的IO监控里容易产生误区的点。</p>
<p>这些误区，一方面是因为工程师想当然，不仔细看文档，不理解底层细节。另一方面是因为Linux内核和监控工具的发展，落后于存储设备硬件的发展，软硬件发展存在脱节，因此监控工具不能反映硬件的真实情况。</p>
<p>纠正这些误区，对这些监控和背后原理理解越深刻，越能评估一个系统性能的真实情况，定位和解决问题也更容易。</p>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Summary:	ASRock Z370M-ITX/ac, 1 x Core i5-8400 2.80GHz, 15.2GB / 16GB 2400MT/s DDR4</span><br><span class="line">System:		ASRock Z370M-ITX/ac</span><br><span class="line">Processors:	1 x Core i5-8400 2.80GHz 100MHz FSB (6 cores)</span><br><span class="line">Memory:		15.2GB / 16GB 2400MT/s DDR4 == 2 x 8GB</span><br><span class="line">Disk:		sda (scsi0): 240GB (0%) JBOD == 1 x LITEON-EGT-240N9S</span><br><span class="line">Disk:		sdb: 100GB JBOD == 1 x INTEL-SSDSA2BZ100G3</span><br><span class="line">Disk:		sdc (scsi2): 1.0TB JBOD == 1 x WDC-WD10JPLX-00MBPT1</span><br><span class="line">OS:		CentOS Linux 7.6.1810 (Core) , Linux 3.10.0-957.10.1.el7.x86_64 x86_64, 64-bit</span><br><span class="line">BIOS:		AMI P1.50 11/16/2017</span><br><span class="line">Hostname:	MiWiFi-R1CM-srv</span><br></pre></td></tr></table></figure>
<p>这是一台普通的x86台式机，sdb是Intel SSD 710 Series，sdc是西数的7200转黑盘。使用这两块盘来做后面的实验。</p>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p>下面介绍四个容易产生误区的指标，分别是%iowait、await、svctm、%util。顺序上会把%util放在svctm之前介绍。</p>
<h3 id="iowait"><a href="#iowait" class="headerlink" title="%iowait"></a>%iowait</h3><ul>
<li>正确：%iowait（wa）是CPU的一种IDLE，%iowait大小不能用来反映IO瓶颈。</li>
<li>误区：（1）%iowait高，CPU很忙。（2）%iowait高，磁盘IO瓶颈。</li>
</ul>
<h4 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h4><p>%iowait（来自mpstat）和wa（来自top、vmstat）是同一个指标，表示在一个采样周期内，CPU空闲在等待未完成的IO请求所占的白分比。iowait的产生要满足两个条件，一是进程在等io，二是等io时没有进程可运行。</p>
<h4 id="误区（1）-iowait高，CPU很忙。"><a href="#误区（1）-iowait高，CPU很忙。" class="headerlink" title="误区（1）%iowait高，CPU很忙。"></a>误区（1）%iowait高，CPU很忙。</h4><p>先看官方文档说明：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">man vmstat</span><br><span class="line">wa: Time spent waiting for IO.  Prior to Linux 2.5.41, included in idle.</span><br><span class="line"></span><br><span class="line">man mpstat</span><br><span class="line">%iowait</span><br><span class="line">Show the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request.</span><br></pre></td></tr></table></figure></p>
<p>文档已经明确显示，%iowait是一种IDLE，尤其在2.5.41以前的旧内核里，%iowait是直接统计在idle里的。既然%iowait的显示的百分比是一种IDLE，它是可以被其它进程使用的。%iowait高，CPU其实很闲，因为其它进程都在随眠。</p>
<h4 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">在这台完全空闲的机器上，对sdc进行随机读，可以看到IOPS大约是60多，这与7200rpm的机械硬盘性能是相符的。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -name=rand_100read_4k</span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1): [r(1)][6.7%][r=252KiB/s,w=0KiB/s][r=63,w=0 IOPS][eta 02m:48s]</span><br><span class="line"></span><br><span class="line">此时，我们看%iowait，可以看到在核心6上，100%的iowait。</span><br><span class="line">top - 22:27:51 up  3:08,  3 users,  load average: 2.37, 2.40, 1.31</span><br><span class="line">Tasks: 157 total,   1 running, 156 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu0  :  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu1  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu2  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu3  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu4  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu5  :  0.0 us,  0.3 sy,  0.0 ni,  0.0 id, 99.7 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 15934084 total, 11211948 free,   290604 used,  4431532 buff/cache</span><br><span class="line">KiB Swap:  8061948 total,  8061948 free,        0 used. 14941848 avail Mem </span><br><span class="line"></span><br><span class="line">这时，我们起一个stress打满CPU看看。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# stress -c 6</span><br><span class="line">stress: info: [9856] dispatching hogs: 6 cpu, 0 io, 0 vm, 0 hdd</span><br><span class="line"></span><br><span class="line">可以看到，起了6个stress打满了6个核心，fio进程还在运行，但是%iowait已经被“吃掉”了，说明这部分IDLE的CPU时间片已经被stress征用了。</span><br><span class="line">top - 22:28:36 up  3:09,  3 users,  load average: 3.63, 2.67, 1.45</span><br><span class="line">Tasks: 162 total,   7 running, 155 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu0  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu1  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu2  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu3  : 99.7 us,  0.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu4  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu5  : 99.7 us,  0.3 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 15934084 total, 11208508 free,   293992 used,  4431584 buff/cache</span><br><span class="line">KiB Swap:  8061948 total,  8061948 free,        0 used. 14938420 avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                           </span><br><span class="line"> 9857 root      20   0    7308     96      0 R 100.0  0.0   0:22.69 stress                                                                            </span><br><span class="line"> 9861 root      20   0    7308     96      0 R 100.0  0.0   0:22.71 stress                                                                            </span><br><span class="line"> 9862 root      20   0    7308     96      0 R 100.0  0.0   0:22.71 stress                                                                            </span><br><span class="line"> 9858 root      20   0    7308     96      0 R  99.7  0.0   0:22.67 stress                                                                            </span><br><span class="line"> 9859 root      20   0    7308     96      0 R  99.7  0.0   0:22.68 stress                                                                            </span><br><span class="line"> 9860 root      20   0    7308     96      0 R  99.7  0.0   0:22.70 stress                                                                            </span><br><span class="line"> 9834 root      20   0 1091604 293556 261636 S   0.3  1.8   0:01.06 fio</span><br></pre></td></tr></table></figure>
<h4 id="误区（2）-iowait高，磁盘IO瓶颈。"><a href="#误区（2）-iowait高，磁盘IO瓶颈。" class="headerlink" title="误区（2）%iowait高，磁盘IO瓶颈。"></a>误区（2）%iowait高，磁盘IO瓶颈。</h4><p>由之前的解释可以看到，这个指标是描述CPU的IDLE的，它与磁盘IO是否到达瓶颈一点关系都没有，它都不是一个用来描述磁盘IO性能的指标。</p>
<h4 id="实验验证-1"><a href="#实验验证-1" class="headerlink" title="实验验证"></a>实验验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">这个实验使用ssd，如下fio命令，在6个进程下，ssd的随机读性能是25k iops，%iowait超过80%。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4k</span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 6 threads</span><br><span class="line">Jobs: 6 (f=6): [r(6)][20.0%][r=97.0MiB/s,w=0KiB/s][r=25.1k,w=0 IOPS][eta 02m:24s]</span><br><span class="line"></span><br><span class="line"> top - 22:45:45 up  3:26,  3 users,  load average: 4.68, 2.59, 1.81</span><br><span class="line">Tasks: 158 total,   1 running, 157 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu0  :  0.7 us,  6.7 sy,  0.0 ni,  3.4 id, 89.2 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu1  :  1.3 us,  6.4 sy,  0.0 ni,  1.3 id, 91.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu2  :  1.3 us,  7.0 sy,  0.0 ni,  3.7 id, 88.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu3  :  0.7 us,  7.0 sy,  0.0 ni,  2.0 id, 90.3 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu4  :  1.3 us,  6.7 sy,  0.0 ni,  1.3 id, 90.6 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu5  :  1.7 us,  7.3 sy,  0.0 ni,  5.2 id, 83.3 wa,  0.0 hi,  2.6 si,  0.0 st</span><br><span class="line">KiB Mem : 15934084 total, 11223276 free,   278992 used,  4431816 buff/cache</span><br><span class="line">KiB Swap:  8061948 total,  8061948 free,        0 used. 14953420 avail Mem </span><br><span class="line"></span><br><span class="line">还是这块盘，ioengine我们从psync改成aio，同时把iodepth从1改成了8，可以看到44k的IOPS，但是%iowait却是0。</span><br><span class="line">这里说明，%iowait大小与磁盘瓶颈毫无关系，由于aio是异步的，CPU不需要IDLE等待IO，也就不会产生%iowait。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k  -runtime=180 -group_reporting -numjobs=6 -name=rand_100read_4k</span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 6 threads</span><br><span class="line">Jobs: 6 (f=6): [r(6)][5.6%][r=173MiB/s,w=0KiB/s][r=44.2k,w=0 IOPS][eta 02m:50s]</span><br><span class="line"></span><br><span class="line">top - 22:49:31 up  3:30,  3 users,  load average: 1.14, 2.61, 2.06</span><br><span class="line">Tasks: 156 total,   1 running, 155 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu0  :  3.0 us,  4.0 sy,  0.0 ni, 93.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu1  :  2.0 us,  3.0 sy,  0.0 ni, 95.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu2  :  0.3 us,  0.7 sy,  0.0 ni, 99.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu3  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu4  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">%Cpu5  :  5.8 us,  6.9 sy,  0.0 ni, 87.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 15934084 total, 11219948 free,   282280 used,  4431856 buff/cache</span><br><span class="line">KiB Swap:  8061948 total,  8061948 free,        0 used. 14950088 avail Mem </span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                           </span><br><span class="line">10091 root      20   0 1431564 281112 261664 S  33.6  1.8   0:26.54 fio</span><br></pre></td></tr></table></figure>
<h3 id="await"><a href="#await" class="headerlink" title="await"></a>await</h3><ul>
<li>正确：表示IO从创建到完成的平均时间，包含IO排队时间+存储设备处理时间。</li>
<li>误区：（1）混淆%iowait和await。（2）认为await高等于磁盘慢。</li>
</ul>
<h4 id="解释-1"><a href="#解释-1" class="headerlink" title="解释"></a>解释</h4><p>await是iostat里的指标，iostat属于sysstat这个rpm包。<br>await表示平均每个IO所需要的时间，包括在队列等待的时间，也包括磁盘控制器处理本次请求的有效时间。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">man iostat</span><br><span class="line">await</span><br><span class="line">The average time (in milliseconds) for I/O requests issued to the device to be served. This includes the  time  spent  by  the requests in queue and the time spent servicing them.</span><br><span class="line"></span><br><span class="line">这里借用blktrace的blkparse显示的各指标点，await是从IO到达block层开始算起，包含排队时间，到最后IO完毕。</span><br><span class="line">Q-------&gt;G------------&gt;I---------&gt;M-------------------&gt;D-----------------------------&gt;C</span><br><span class="line">|-Q time-|-Insert time-|</span><br><span class="line">|--------- merge time ------------|-merge with other IO|</span><br><span class="line">|----------------scheduler time time-------------------|---driver,adapter,storagetime--|</span><br></pre></td></tr></table></figure></p>
<h4 id="误区（1）混淆-iowait和await。"><a href="#误区（1）混淆-iowait和await。" class="headerlink" title="误区（1）混淆%iowait和await。"></a>误区（1）混淆%iowait和await。</h4><p>在工作中，我遇到过几次运维和研发人员混淆这两个概念的，弄清楚并在表述的时候注意即可。</p>
<h4 id="误区（2）认为await高等于磁盘慢。"><a href="#误区（2）认为await高等于磁盘慢。" class="headerlink" title="误区（2）认为await高等于磁盘慢。"></a>误区（2）认为await高等于磁盘慢。</h4><p>await包含了队列时间，我们只需要保持磁盘压力不变的情况下，增加队列深度即可验证这个问题。</p>
<h4 id="实验验证-2"><a href="#实验验证-2" class="headerlink" title="实验验证"></a>实验验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">这里，我们限制IOPS为100，先用队列深度8，可以看到await 80。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 8 -thread -rw=randread -ioengine=libaio -bs=4k  -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100</span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=8</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1), 0-100 IOPS: [r(1)][5.6%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:50s]</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00   97.00    0.00     0.38     0.00     8.00     8.00   84.79   84.79    0.00  10.31 100.00</span><br><span class="line">sdb               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line"></span><br><span class="line">还是限制IOPS为100，队列深度调高到16，可以看到，IOPS不变的情况下，await增加到110左右。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdc -direct=1 -iodepth 16 -thread -rw=randread -ioengine=libaio -bs=4k  -runtime=180 -group_reporting -numjobs=1 -name=rand_100read_4k -rate_iops=100</span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 1 thread</span><br><span class="line">Jobs: 1 (f=1), 0-100 IOPS: [r(1)][8.3%][r=400KiB/s,w=0KiB/s][r=100,w=0 IOPS][eta 02m:45s]</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00  101.00    0.00     0.39     0.00     8.00    11.93  109.34  109.34    0.00   9.86  99.60</span><br><span class="line">sdb               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br></pre></td></tr></table></figure>
<h3 id="util"><a href="#util" class="headerlink" title="%util"></a>%util</h3><ul>
<li>正确：iostat里的%util并不能准确反映存储设备使用率（或者称为饱和率）。</li>
<li>误区：%util就是存储设备硬件的使用率，达到100%时就到磁盘瓶颈了。</li>
</ul>
<h4 id="解释-2"><a href="#解释-2" class="headerlink" title="解释"></a>解释</h4><p>%util估算了一个使用率，但是存储设备的使用率以及是否饱和，是没有接口告诉Linux系统的。<br>%util通过/proc/diskstats计算得到，不关心等待在队里里面IO的个数，它只关心队列中有没有IO。。<br>整个计算方式把存储设备当做只能串行处理IO的磁盘，当使用支持并发处理IO的存储设备时，此项就不准确了。<br>当%util是100%时，代表Linux队列里一直有IO，但不能代表硬件存储设备已经饱和。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在sysstat网站的最新文档中也已经注明： But for devices serving requests in parallel, such as RAID arrays and modern SSDs, this number does not reflect their performance limits.</span><br><span class="line"></span><br><span class="line">文档地址：http://sebastien.godard.pagesperso-orange.fr/man_iostat.html</span><br><span class="line"></span><br><span class="line">%util</span><br><span class="line">Percentage of elapsed time during which I/O requests were issued to the device (bandwidth utilization for the device).  Device saturation occurs when this value is close to 100%.</span><br></pre></td></tr></table></figure></p>
<h4 id="实验验证-3"><a href="#实验验证-3" class="headerlink" title="实验验证"></a>实验验证</h4><p>由于%util是以单并发的存储设备设计的，只要是支持多并发的存储设备，%util就不准确了。提升并发数，即可验证这个问题。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">同样的测试用例，我们num-jobs从4改到8，可以看到，使用率都是100%，但是IOPS有巨大的不同。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k </span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 4 threads</span><br><span class="line">Jobs: 4 (f=4): [r(4)][3.3%][r=74.7MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:54s]</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdb               0.00     0.00 18078.00    0.00    70.62     0.00     8.00     3.57    0.20    0.20    0.00   0.06 100.00</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -numjobs=8 -name=rand_100read_4k </span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 8 threads</span><br><span class="line">Jobs: 8 (f=8): [r(8)][7.8%][r=110MiB/s,w=0KiB/s][r=28.2k,w=0 IOPS][eta 02m:46s]</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdb               0.00     0.00 28233.00    0.00   110.29     0.00     8.00     7.31    0.26    0.26    0.00   0.04 100.00</span><br></pre></td></tr></table></figure></p>
<h3 id="svctm"><a href="#svctm" class="headerlink" title="svctm"></a>svctm</h3><ul>
<li>正确：iostat里的svctm并不能准确反映存储设备的处理时间。</li>
<li>误区：svctm就是存储设备硬件处理IO的时间。</li>
</ul>
<h4 id="解释-3"><a href="#解释-3" class="headerlink" title="解释"></a>解释</h4><p>从官方文档可以看到，Do not trust this field any more.<br>实际上，iostat获取这个svctm仅是通过一个简单计算。<br>iostat计算svctm需要使用%util，但%util在多并发IO里，本身就是不准确的，所以间接造成svctm也不准确。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svctm</span><br><span class="line">The  average  service time (in milliseconds) for I/O requests that were issued to the device. Warning! Do not trust this field any more.  This field will be removed in a future sysstat version.</span><br></pre></td></tr></table></figure></p>
<h4 id="实验验证-4"><a href="#实验验证-4" class="headerlink" title="实验验证"></a>实验验证</h4><p>对于相同的IO模型，存储设备的处理时间都应该是一样的。如果压力越大，存储设备处理时间应该越长才对。我们验证svctm是否和真实情况一样。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">我们使用SSD做实验，可以看到，当从4个并发提升到32个并发时，IOPS从19k提升到44k，但是svctm却从0.05ms下降到0.02ms，明显不符合现实。</span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -numjobs=4 -name=rand_100read_4k </span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 4 threads</span><br><span class="line">Jobs: 4 (f=4): [r(4)][5.0%][r=74.6MiB/s,w=0KiB/s][r=19.1k,w=0 IOPS][eta 02m:51s]</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdb               0.00     0.00 19069.00    0.00    74.49     0.00     8.00     3.90    0.20    0.20    0.00   0.05 100.00</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@MiWiFi-R1CM-srv ~]# fio -filename=/dev/sdb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k  -runtime=180 -group_reporting -numjobs=32 -name=rand_100read_4k </span><br><span class="line">rand_100read_4k: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1</span><br><span class="line">...</span><br><span class="line">fio-3.1</span><br><span class="line">Starting 32 threads</span><br><span class="line">Jobs: 32 (f=32): [r(32)][31.7%][r=172MiB/s,w=0KiB/s][r=44.1k,w=0 IOPS][eta 02m:03s]</span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdc               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00</span><br><span class="line">sdb               0.00     0.00 44080.00    0.00   172.19     0.00     8.00    31.37    0.71    0.71    0.00   0.02 100.00</span><br></pre></td></tr></table></figure></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>%iowait并没有提供什么有效信息，因为它是描述IDLE的。</li>
<li>%iowait大小受CPU的负载变化而变化，这个指标如果很大，除了能说明CPU很闲在等待IO以外，并不能反映IO压力或者瓶颈。另外，aio不会使CPU产生%iowait。</li>
<li>iostat提供了基本的监控数据，但是分析IO瓶颈，关键是去看Linux的IO的监控指标是否打满了存储设备的真实性能，因此必须对存储设备在当前IO模型下具备的真实性能有所了解。</li>
<li>这些值虽然不够准确，但是在生产环境中，仍然具备参考意义：当你的业务类型和压力没有任何变化时，如果这些值偏离了基线（baseline）或者历史平均值，则你需要去排查是否哪里出了问题。</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>本文讲解并不深入，更多的是实验思路。建议阅读下列文章，包含原理性的解释，一并致谢：<br><a href="https://mp.weixin.qq.com/s?__biz=MzAwMDUwNDgxOA==&amp;mid=2652663269&amp;idx=1&amp;sn=f0bddde33fd4c57bd708b3b14a004e98&amp;chksm=810f2b78b678a26e6e36b9e1c077d35af1ca7fca9c1b4f241d81d4618af949551079dc364a7f&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">朱辉(茶水)： Linux Kernel iowait 时间的代码原理</a></p>
<p><a href="http://bean-li.github.io/dive-into-iostat/" target="_blank" rel="noopener">深入理解iostat</a></p>
<p><a href="https://www.jianshu.com/p/13de0aea7c1e" target="_blank" rel="noopener">辩证看待 iostat</a></p>
<p><a href="https://github.com/zhishutech/tech-blog-en2zh/blob/master/mysql/1-zh-Looking%20at%20Disk%20Utilization%20and%20Saturation.md" target="_blank" rel="noopener">深入理解磁盘IO利用率及饱和度</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          


          


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Roger K</p>
              <p class="site-description motion-element" itemprop="description">个人小站。致力于为运维及研发提供准确、靠谱的运维资料和经验。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zw1m" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:20207593@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Roger K</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
